{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6, Day 1: Introduction to Natural Language Processing\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand NLP fundamentals\n",
    "- Learn text preprocessing techniques\n",
    "- Master basic NLP tasks\n",
    "- Practice implementing NLP pipelines\n",
    "\n",
    "## Topics Covered\n",
    "1. Text Preprocessing\n",
    "2. Tokenization\n",
    "3. Text Representation\n",
    "4. Basic NLP Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def text_preprocessing_example():\n",
    "    # Sample text\n",
    "    text = \"\"\"\n",
    "    Natural Language Processing (NLP) is a branch of artificial intelligence\n",
    "    that helps computers understand, interpret, and manipulate human language.\n",
    "    NLP combines computational linguistics, machine learning, and deep learning\n",
    "    to process and analyze large amounts of natural language data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenization\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Original Text:\")\n",
    "    print(text)\n",
    "    \n",
    "    print(\"\\nSentences:\")\n",
    "    for i, sent in enumerate(sentences, 1):\n",
    "        print(f\"{i}. {sent.strip()}\")\n",
    "    \n",
    "    print(\"\\nOriginal Words:\")\n",
    "    print(words[:20])\n",
    "    \n",
    "    print(\"\\nFiltered Words (without stopwords):\")\n",
    "    print(filtered_words[:20])\n",
    "    \n",
    "    print(\"\\nStemmed Words:\")\n",
    "    print(stemmed_words[:20])\n",
    "    \n",
    "    print(\"\\nLemmatized Words:\")\n",
    "    print(lemmatized_words[:20])\n",
    "\n",
    "text_preprocessing_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def text_representation_example():\n",
    "    # Sample documents\n",
    "    documents = [\n",
    "        \"Natural language processing is fascinating.\",\n",
    "        \"Machine learning algorithms are powerful.\",\n",
    "        \"Deep learning revolutionized NLP.\",\n",
    "        \"Processing natural language requires understanding.\"\n",
    "    ]\n",
    "    \n",
    "    # Bag of Words\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    bow_matrix = count_vectorizer.fit_transform(documents)\n",
    "    \n",
    "    # TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "    \n",
    "    # Create DataFrames for visualization\n",
    "    bow_df = pd.DataFrame(\n",
    "        bow_matrix.toarray(),\n",
    "        columns=count_vectorizer.get_feature_names_out()\n",
    "    )\n",
    "    \n",
    "    tfidf_df = pd.DataFrame(\n",
    "        tfidf_matrix.toarray(),\n",
    "        columns=tfidf_vectorizer.get_feature_names_out()\n",
    "    )\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    sns.heatmap(bow_df, annot=True, fmt='.0f', cmap='YlOrRd')\n",
    "    plt.title('Bag of Words Representation')\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Documents')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    sns.heatmap(tfidf_df, annot=True, fmt='.2f', cmap='YlOrRd')\n",
    "    plt.title('TF-IDF Representation')\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Documents')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "text_representation_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic NLP Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def basic_nlp_tasks():\n",
    "    # Part-of-Speech Tagging\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    text = \"The quick brown fox jumps over the lazy dog\"\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Named Entity Recognition\n",
    "    nltk.download('maxent_ne_chunker')\n",
    "    nltk.download('words')\n",
    "    text = \"Apple Inc. was founded by Steve Jobs in California\"\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    named_entities = nltk.ne_chunk(pos_tags)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Part-of-Speech Tagging:\")\n",
    "    for word, tag in pos_tags:\n",
    "        print(f\"{word}: {tag}\")\n",
    "    \n",
    "    print(\"\\nNamed Entity Recognition:\")\n",
    "    print(named_entities)\n",
    "\n",
    "basic_nlp_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 1: Text Classification\n",
    "\n",
    "def text_classification_exercise():\n",
    "    # Sample dataset\n",
    "    texts = [\n",
    "        \"This movie was fantastic! Great acting and plot.\",\n",
    "        \"Terrible waste of time. Poor acting and boring story.\",\n",
    "        \"Amazing film, highly recommended!\",\n",
    "        \"Don't waste your money on this movie.\",\n",
    "        \"Excellent performance by the entire cast.\"\n",
    "    ]\n",
    "    labels = [1, 0, 1, 0, 1]  # 1: positive, 0: negative\n",
    "    \n",
    "    print(\"Task: Create a simple sentiment classifier\")\n",
    "    print(\"1. Preprocess the texts\")\n",
    "    print(\"2. Create text representations\")\n",
    "    print(\"3. Train a classifier\")\n",
    "    print(\"4. Evaluate performance\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "text_classification_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 2: Text Analysis\n",
    "\n",
    "def text_analysis_exercise():\n",
    "    text = \"\"\"\n",
    "    The field of artificial intelligence has seen remarkable progress in recent years.\n",
    "    Machine learning algorithms have revolutionized many industries, from healthcare\n",
    "    to finance. Natural language processing, a subset of AI, has enabled computers\n",
    "    to understand and generate human language with increasing accuracy.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Task: Analyze the text\")\n",
    "    print(\"1. Calculate word frequencies\")\n",
    "    print(\"2. Find key phrases\")\n",
    "    print(\"3. Identify main topics\")\n",
    "    print(\"4. Visualize results\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "text_analysis_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCQ Quiz\n",
    "\n",
    "1. What is tokenization?\n",
    "   - a) Text compression\n",
    "   - b) Breaking text into units\n",
    "   - c) Text generation\n",
    "   - d) Language translation\n",
    "\n",
    "2. What are stopwords?\n",
    "   - a) Important keywords\n",
    "   - b) Common words with little meaning\n",
    "   - c) Punctuation marks\n",
    "   - d) Named entities\n",
    "\n",
    "3. What is stemming?\n",
    "   - a) Word creation\n",
    "   - b) Reducing words to root form\n",
    "   - c) Part-of-speech tagging\n",
    "   - d) Sentence parsing\n",
    "\n",
    "4. What does TF-IDF measure?\n",
    "   - a) Word count\n",
    "   - b) Word importance\n",
    "   - c) Text similarity\n",
    "   - d) Grammar accuracy\n",
    "\n",
    "5. What is lemmatization?\n",
    "   - a) Word counting\n",
    "   - b) Converting to proper word form\n",
    "   - c) Text summarization\n",
    "   - d) Language detection\n",
    "\n",
    "6. What is part-of-speech tagging?\n",
    "   - a) Word counting\n",
    "   - b) Grammar checking\n",
    "   - c) Word role labeling\n",
    "   - d) Text generation\n",
    "\n",
    "7. What is named entity recognition?\n",
    "   - a) Grammar checking\n",
    "   - b) Identifying proper nouns\n",
    "   - c) Word counting\n",
    "   - d) Text translation\n",
    "\n",
    "8. What is the bag of words model?\n",
    "   - a) Grammar model\n",
    "   - b) Word frequency representation\n",
    "   - c) Translation model\n",
    "   - d) Language model\n",
    "\n",
    "9. What is corpus in NLP?\n",
    "   - a) Text editor\n",
    "   - b) Collection of texts\n",
    "   - c) Programming language\n",
    "   - d) Machine learning model\n",
    "\n",
    "10. What is the purpose of text preprocessing?\n",
    "    - a) Text generation\n",
    "    - b) Clean and standardize text\n",
    "    - c) Language translation\n",
    "    - d) Grammar checking\n",
    "\n",
    "Answers: 1-b, 2-b, 3-b, 4-b, 5-b, 6-c, 7-b, 8-b, 9-b, 10-b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}