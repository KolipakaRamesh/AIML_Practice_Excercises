{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7, Day 4: Face Detection and Recognition\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand face detection concepts\n",
    "- Learn face recognition techniques\n",
    "- Master facial landmark detection\n",
    "- Practice implementing face analysis systems\n",
    "\n",
    "## Topics Covered\n",
    "1. Face Detection\n",
    "2. Face Recognition\n",
    "3. Facial Landmarks\n",
    "4. Face Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import dlib\n",
    "from PIL import Image\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def face_detection_example():\n",
    "    # Load face cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "    )\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread('sample.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    \n",
    "    # Draw rectangles around faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display result\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Found {len(faces)} faces')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "face_detection_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def face_recognition_example():\n",
    "    # Load known face\n",
    "    known_image = face_recognition.load_image_file('known_face.jpg')\n",
    "    known_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "    \n",
    "    # Load test image\n",
    "    test_image = face_recognition.load_image_file('test_image.jpg')\n",
    "    face_locations = face_recognition.face_locations(test_image)\n",
    "    face_encodings = face_recognition.face_encodings(test_image, face_locations)\n",
    "    \n",
    "    # Compare faces\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        matches = face_recognition.compare_faces([known_encoding], face_encoding)\n",
    "        \n",
    "        if matches[0]:\n",
    "            color = (0, 255, 0)  # Green for match\n",
    "            label = 'Match'\n",
    "        else:\n",
    "            color = (0, 0, 255)  # Red for no match\n",
    "            label = 'Unknown'\n",
    "        \n",
    "        # Draw box\n",
    "        cv2.rectangle(test_image, (left, top), (right, bottom), color, 2)\n",
    "        \n",
    "        # Add label\n",
    "        cv2.putText(test_image, label, (left, top-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    # Display result\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(test_image)\n",
    "    plt.title('Face Recognition Results')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "face_recognition_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Facial Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def facial_landmarks_example():\n",
    "    # Initialize face detector and landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread('sample.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    # For each face, detect landmarks\n",
    "    for face in faces:\n",
    "        # Get landmarks\n",
    "        landmarks = predictor(gray, face)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        for n in range(68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "    \n",
    "    # Display result\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Facial Landmarks')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "facial_landmarks_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Face Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def face_analysis_example():\n",
    "    # Load image\n",
    "    image = cv2.imread('sample.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Initialize detectors\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "    )\n",
    "    eye_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + 'haarcascade_eye.xml'\n",
    "    )\n",
    "    smile_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + 'haarcascade_smile.xml'\n",
    "    )\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw face rectangle\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Detect eyes\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "        \n",
    "        # Detect smile\n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray, 1.7, 20)\n",
    "        for (sx, sy, sw, sh) in smiles:\n",
    "            cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (0, 0, 255), 2)\n",
    "    \n",
    "    # Display result\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Face Analysis')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "face_analysis_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 1: Face Detection System\n",
    "\n",
    "def face_detection_exercise():\n",
    "    print(\"Task: Build a face detection system\")\n",
    "    print(\"1. Load and process image\")\n",
    "    print(\"2. Detect faces\")\n",
    "    print(\"3. Draw bounding boxes\")\n",
    "    print(\"4. Display results\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "face_detection_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 2: Face Recognition System\n",
    "\n",
    "def face_recognition_exercise():\n",
    "    print(\"Task: Implement face recognition\")\n",
    "    print(\"1. Create face database\")\n",
    "    print(\"2. Extract face encodings\")\n",
    "    print(\"3. Compare faces\")\n",
    "    print(\"4. Visualize matches\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "face_recognition_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCQ Quiz\n",
    "\n",
    "1. What is face detection?\n",
    "   - a) Face recognition\n",
    "   - b) Face localization\n",
    "   - c) Face analysis\n",
    "   - d) Face generation\n",
    "\n",
    "2. What is face recognition?\n",
    "   - a) Face detection\n",
    "   - b) Face identification\n",
    "   - c) Face generation\n",
    "   - d) Face tracking\n",
    "\n",
    "3. What are facial landmarks?\n",
    "   - a) Face detection\n",
    "   - b) Key face points\n",
    "   - c) Face recognition\n",
    "   - d) Face tracking\n",
    "\n",
    "4. What is Haar cascade?\n",
    "   - a) Neural network\n",
    "   - b) Feature detector\n",
    "   - c) Face generator\n",
    "   - d) Image filter\n",
    "\n",
    "5. What is face embedding?\n",
    "   - a) Face detection\n",
    "   - b) Face vector representation\n",
    "   - c) Face tracking\n",
    "   - d) Face generation\n",
    "\n",
    "6. What is face alignment?\n",
    "   - a) Face detection\n",
    "   - b) Face normalization\n",
    "   - c) Face recognition\n",
    "   - d) Face tracking\n",
    "\n",
    "7. What is face verification?\n",
    "   - a) Face detection\n",
    "   - b) Face matching\n",
    "   - c) Face tracking\n",
    "   - d) Face generation\n",
    "\n",
    "8. What is face clustering?\n",
    "   - a) Face detection\n",
    "   - b) Face grouping\n",
    "   - c) Face tracking\n",
    "   - d) Face generation\n",
    "\n",
    "9. What is face tracking?\n",
    "   - a) Face detection\n",
    "   - b) Face movement following\n",
    "   - c) Face recognition\n",
    "   - d) Face generation\n",
    "\n",
    "10. What is face spoofing detection?\n",
    "    - a) Face recognition\n",
    "    - b) Fake face detection\n",
    "    - c) Face tracking\n",
    "    - d) Face generation\n",
    "\n",
    "Answers: 1-b, 2-b, 3-b, 4-b, 5-b, 6-b, 7-b, 8-b, 9-b, 10-b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}