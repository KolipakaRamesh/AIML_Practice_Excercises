{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUz8pTc/FOd8jGOgux+6T1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KolipakaRamesh/AIML_Practice_Excercises/blob/main/Transformer_Py_Step_By_Step.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCRFW8BAZVrg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee91e831"
      },
      "source": [
        "## Understanding the Transformer Code - Step by Step\n",
        "\n",
        "Let's break down the code into smaller, more manageable parts with detailed explanations.\n",
        "\n",
        "### 1. Imports\n",
        "\n",
        "This section imports the necessary libraries from PyTorch and Matplotlib.\n",
        "\n",
        "*   `torch`: The main PyTorch library for building neural networks.\n",
        "*   `torch.nn`: Contains modules and classes for building neural network layers.\n",
        "*   `torch.nn.functional`: Provides functions for neural network operations (like softmax).\n",
        "*   `math`: Used for mathematical operations, specifically for the positional encoding.\n",
        "*   `matplotlib.pyplot`: Used for plotting graphs, like the training loss.\n",
        "*   `torch.optim`: Contains optimization algorithms, like Adam, used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c228d8a1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6191f1af"
      },
      "source": [
        "### 2. Positional Encoding\n",
        "\n",
        "The `PositionalEncoding` class adds information about the position of each token in the sequence. Transformers process sequences in parallel, so they don't inherently know the order of tokens. Positional encoding provides this crucial information.\n",
        "\n",
        "The encoding is done using sine and cosine functions of different frequencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04035472"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # Create a matrix of shape (max_len, d_model) to store the positional encodings\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # Create a tensor of positions (0, 1, 2, ...)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # Calculate the division term for the sine and cosine arguments\n",
        "        # This creates frequencies that decrease exponentially\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # Apply sine to even indices in the positional encoding matrix\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "\n",
        "        # Apply cosine to odd indices in the positional encoding matrix\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Add an extra dimension for the batch size (even though we only have one encoding matrix)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # Register the positional encoding matrix as a buffer.\n",
        "        # Buffers are tensors that are part of the module's state but not its parameters (they are not updated by gradients).\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add the positional encoding to the input tensor x\n",
        "        # We slice the positional encoding to match the sequence length of the input tensor\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65c0bcdd"
      },
      "source": [
        "### 3. Scaled Dot-Product Attention\n",
        "\n",
        "This is the fundamental attention mechanism used in the Transformer. It calculates the attention between a query and a set of keys and values.\n",
        "\n",
        "The process involves:\n",
        "1.  Calculating the dot product of the Query and Key tensors.\n",
        "2.  Scaling the dot product by the square root of the dimension of the keys (`d_k`) to prevent large values from dominating the softmax.\n",
        "3.  Optionally applying a mask to ignore certain positions (e.g., padding tokens or future tokens in the decoder).\n",
        "4.  Applying a softmax function to get attention weights, which represent how much attention each position in the query attends to each position in the key.\n",
        "5.  Multiplying the attention weights by the Value tensor to get the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7f1fc89"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask=None):\n",
        "    \"\"\"\n",
        "    Calculates scaled dot-product attention.\n",
        "\n",
        "    Args:\n",
        "        query (torch.Tensor): Query tensor of shape (batch_size, num_heads, seq_len, d_k).\n",
        "        key (torch.Tensor): Key tensor of shape (batch_size, num_heads, seq_len, d_k).\n",
        "        value (torch.Tensor): Value tensor of shape (batch_size, num_heads, seq_len, d_v).\n",
        "        mask (torch.Tensor, optional): Mask tensor to prevent attention to certain positions.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - torch.Tensor: Output tensor after attention.\n",
        "            - torch.Tensor: Attention weights.\n",
        "    \"\"\"\n",
        "    d_k = query.size(-1)\n",
        "    scaled_dot_product = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_dot_product = scaled_dot_product.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "    attention_weights = F.softmax(scaled_dot_product, dim=-1)\n",
        "    output = torch.matmul(attention_weights, value)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88e8b5e1"
      },
      "source": [
        "### 4. Multi-Head Attention\n",
        "\n",
        "Multi-Head Attention allows the model to jointly attend to information from different representation subspaces at different positions. It does this by:\n",
        "\n",
        "1.  Linearly projecting the Query, Key, and Value tensors multiple times with different learned linear projections. These projections are split into a specified number of \"heads.\"\n",
        "2.  Performing scaled dot-product attention in parallel for each of these heads.\n",
        "3.  Concatenating the output of each attention head.\n",
        "4.  Applying a final linear projection to the concatenated output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91288db6"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0 # Ensure the model dimension is divisible by the number of heads\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads # Dimension of each attention head\n",
        "\n",
        "        # Linear layers for projecting Query, Key, Value, and the final output\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # Apply linear projections and reshape for multi-head attention\n",
        "        # The view operation changes the tensor shape, and transpose rearranges the dimensions\n",
        "        q = self.W_q(query).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        k = self.W_k(key).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        v = self.W_v(value).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Perform scaled dot-product attention for each head\n",
        "        attention_output, _ = scaled_dot_product_attention(q, k, v, mask=mask)\n",
        "\n",
        "        # Reshape and apply final linear projection\n",
        "        # contiguous() is needed before view() if the tensor's memory layout is not contiguous\n",
        "        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
        "        output = self.W_o(attention_output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2eaf697"
      },
      "source": [
        "### 5. Feedforward and Layer Normalization\n",
        "\n",
        "These components are applied after the attention mechanisms within each encoder and decoder layer.\n",
        "\n",
        "*   **Feedforward Network**: This is a simple neural network with two linear layers and an activation function. It's applied independently to each position in the sequence and helps the model process the information learned by the attention layers.\n",
        "*   **Layer Normalization**: This technique helps stabilize the training of deep networks by normalizing the activations of each layer across the features. It's typically applied before or after the attention and feedforward sub-layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbc869b5"
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple feedforward network with two linear layers and ReLU activation,\n",
        "    followed by Layer Normalization.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            d_model (int): The dimension of the input and output.\n",
        "            d_ff (int): The dimension of the hidden layer.\n",
        "        \"\"\"\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after passing through the feedforward network.\n",
        "        \"\"\"\n",
        "        return self.linear2(self.relu(self.linear1(x)))\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Layer Normalization module.\n",
        "    \"\"\"\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            features (int): The number of features to normalize.\n",
        "            eps (float): A small value added to the variance to avoid division by zero.\n",
        "        \"\"\"\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after applying layer normalization.\n",
        "        \"\"\"\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeb260c6"
      },
      "source": [
        "### 6. Encoder Layer Implementation\n",
        "\n",
        "This class represents a single layer of the Transformer encoder. The encoder's role is to process the input sequence and create a representation of it.\n",
        "\n",
        "Each encoder layer consists of two main sub-layers:\n",
        "1.  **Multi-Head Self-Attention**: This allows the encoder to weigh the importance of different words in the input sequence relative to each other.\n",
        "2.  **Feedforward Network**: A simple neural network applied to each position independently.\n",
        "\n",
        "Both sub-layers are followed by a residual connection and Layer Normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f90b78fb"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    A single encoder layer in a Transformer model.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            d_model (int): The dimension of the input and output.\n",
        "            num_heads (int): The number of attention heads.\n",
        "            d_ff (int): The dimension of the hidden layer in the feedforward network.\n",
        "            dropout (float): The dropout rate.\n",
        "        \"\"\"\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = LayerNorm(d_model)\n",
        "        self.norm2 = LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor to the encoder layer.\n",
        "            mask (torch.Tensor, optional): Mask tensor for self-attention.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor from the encoder layer.\n",
        "        \"\"\"\n",
        "        # LayerNorm before self-attention\n",
        "        normalized_x = self.norm1(x)\n",
        "        # Self-attention with residual connection and dropout\n",
        "        attn_output = self.self_attn(normalized_x, normalized_x, normalized_x, mask)\n",
        "        x = x + self.dropout(attn_output)\n",
        "\n",
        "        # LayerNorm before feedforward\n",
        "        normalized_x = self.norm2(x)\n",
        "        # Feedforward with residual connection and dropout\n",
        "        ff_output = self.feed_forward(normalized_x)\n",
        "        x = x + self.dropout(ff_output)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "193bcd27"
      },
      "source": [
        "### 7. Decoder Layer Implementation\n",
        "\n",
        "This class represents a single layer of the Transformer decoder. The decoder's role is to generate the output sequence based on the encoder's output and the previously generated tokens.\n",
        "\n",
        "Each decoder layer consists of three main sub-layers:\n",
        "1.  **Masked Multi-Head Self-Attention**: Similar to the encoder's self-attention, but masked to prevent attending to future tokens in the output sequence during training (to simulate the sequential generation process).\n",
        "2.  **Multi-Head Encoder-Decoder Attention**: This attention mechanism allows the decoder to attend to the output of the encoder, focusing on the most relevant parts of the input sequence for generating the current output token.\n",
        "3.  **Feedforward Network**: A simple neural network applied to each position independently.\n",
        "\n",
        "All sub-layers are followed by a residual connection and Layer Normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "021ae5f8"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    A single decoder layer in a Transformer model.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            d_model (int): The dimension of the input and output.\n",
        "            num_heads (int): The number of attention heads.\n",
        "            d_ff (int): The dimension of the hidden layer in the feedforward network.\n",
        "            dropout (float): The dropout rate.\n",
        "        \"\"\"\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.encoder_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = LayerNorm(d_model)\n",
        "        self.norm2 = LayerNorm(d_model)\n",
        "        self.norm3 = LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor to the decoder layer (target sequence).\n",
        "            encoder_output (torch.Tensor): Output tensor from the encoder.\n",
        "            src_mask (torch.Tensor, optional): Mask tensor for encoder-decoder attention.\n",
        "            tgt_mask (torch.Tensor, optional): Mask tensor for masked self-attention in the decoder.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor from the decoder layer.\n",
        "        \"\"\"\n",
        "        # Masked self-attention\n",
        "        normalized_x = self.norm1(x)\n",
        "        self_attn_output = self.self_attn(normalized_x, normalized_x, normalized_x, mask=tgt_mask)\n",
        "        x = x + self.dropout(self_attn_output)\n",
        "\n",
        "        # Encoder-decoder attention\n",
        "        normalized_x = self.norm2(x)\n",
        "        encoder_attn_output = self.encoder_attn(normalized_x, encoder_output, encoder_output, mask=src_mask)\n",
        "        x = x + self.dropout(encoder_attn_output)\n",
        "\n",
        "        # Feedforward\n",
        "        normalized_x = self.norm3(x)\n",
        "        ff_output = self.feed_forward(normalized_x)\n",
        "        x = x + self.dropout(ff_output)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b48d0e3"
      },
      "source": [
        "### 8. Transformer Model Implementation\n",
        "\n",
        "This class puts together the Encoder and Decoder layers to form the complete Transformer architecture. It includes:\n",
        "\n",
        "*   **Embedding Layers**: To convert input and target tokens into numerical representations (vectors).\n",
        "*   **Positional Encoding**: Added to the embeddings to incorporate sequence order information.\n",
        "*   **Encoder Stack**: Multiple Encoder layers stacked on top of each other to process the input sequence.\n",
        "*   **Decoder Stack**: Multiple Decoder layers stacked on top of each other to generate the output sequence.\n",
        "*   **Final Linear Layer**: To project the decoder's output to the size of the target vocabulary, giving probabilities for each possible next token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a6470de"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    A complete Transformer model architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_encoder_layers, num_decoder_layers, d_ff, dropout):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src_vocab_size (int): The size of the source vocabulary.\n",
        "            tgt_vocab_size (int): The size of the target vocabulary.\n",
        "            d_model (int): The dimension of the model's embeddings.\n",
        "            num_heads (int): The number of attention heads.\n",
        "            num_encoder_layers (int): The number of encoder layers.\n",
        "            num_decoder_layers (int): The number of decoder layers.\n",
        "            d_ff (int): The dimension of the hidden layer in the feedforward networks.\n",
        "            dropout (float): The dropout rate.\n",
        "        \"\"\"\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Embedding layers\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        # Positional Encoding\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "\n",
        "        # Encoder stack\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_encoder_layers)])\n",
        "\n",
        "        # Decoder stack\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_decoder_layers)])\n",
        "\n",
        "        # Final linear layer\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src (torch.Tensor): Source sequence tensor.\n",
        "            tgt (torch.Tensor): Target sequence tensor.\n",
        "            src_mask (torch.Tensor, optional): Mask for the source sequence.\n",
        "            tgt_mask (torch.Tensor, optional): Mask for the target sequence.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor representing the predicted target sequence.\n",
        "        \"\"\"\n",
        "        # Apply embeddings and positional encoding\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.src_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.tgt_embedding(tgt)))\n",
        "\n",
        "        # Pass through encoder stack\n",
        "        encoder_output = src_embedded\n",
        "        for encoder_layer in self.encoder_layers:\n",
        "            encoder_output = encoder_layer(encoder_output, src_mask)\n",
        "\n",
        "        # Pass through decoder stack\n",
        "        decoder_output = tgt_embedded\n",
        "        for decoder_layer in self.decoder_layers:\n",
        "            decoder_output = decoder_layer(decoder_output, encoder_output, src_mask, tgt_mask)\n",
        "\n",
        "        # Apply final linear layer\n",
        "        output = self.fc_out(decoder_output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0e60c0e"
      },
      "source": [
        "### 9. Tokenizer and Dummy Data\n",
        "\n",
        "This section sets up a simple vocabulary and creates dummy input and target sequences to demonstrate how the model works.\n",
        "\n",
        "*   **Vocabulary**: A list of all possible words the model can understand.\n",
        "*   **Token Mapping**: Dictionaries to convert words to numbers (indices) and vice versa.\n",
        "*   **Tokenizer Function**: A simple function to split text into words and convert them to their corresponding indices.\n",
        "*   **Dummy Data**: Example source and target sequences converted into tensors that the model can process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d236bedd",
        "outputId": "f497ee65-3cc9-48b4-f5d5-26571a3c34df"
      },
      "source": [
        "# Define a simple vocabulary and token mapping\n",
        "vocab = ['<PAD>', '<SOS>', 'hello', 'world', 'transformer', 'model', 'pytorch', 'sequence', 'encoding', 'attention', 'feedforward', 'layer', 'normalization', 'encoder', 'decoder']\n",
        "\n",
        "# Create token to index and index to token mappings\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for idx, word in enumerate(vocab)}\n",
        "\n",
        "# Simple tokenizer function\n",
        "def tokenize(text, word_to_idx):\n",
        "    return [word_to_idx.get(word, word_to_idx['<PAD>']) for word in text.split()]\n",
        "\n",
        "# Generate dummy data\n",
        "dummy_src_text = \"hello transformer model\"\n",
        "dummy_tgt_text = \"hello pytorch sequence\"\n",
        "\n",
        "dummy_src_tokens = tokenize(dummy_src_text, word_to_idx)\n",
        "dummy_tgt_tokens = tokenize(dummy_tgt_text, word_to_idx)\n",
        "\n",
        "dummy_src_tensor = torch.LongTensor(dummy_src_tokens).unsqueeze(0) # Add batch dimension\n",
        "dummy_tgt_tensor = torch.LongTensor(dummy_tgt_tokens).unsqueeze(0) # Add batch dimension\n",
        "\n",
        "print(\"Source Text:\", dummy_src_text)\n",
        "print(\"Source Tokens:\", dummy_src_tokens)\n",
        "print(\"Source Tensor:\", dummy_src_tensor)\n",
        "print(\"\\nTarget Text:\", dummy_tgt_text)\n",
        "print(\"Target Tokens:\", dummy_tgt_tokens)\n",
        "print(\"Target Tensor:\", dummy_tgt_tensor)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Text: hello transformer model\n",
            "Source Tokens: [2, 4, 5]\n",
            "Source Tensor: tensor([[2, 4, 5]])\n",
            "\n",
            "Target Text: hello pytorch sequence\n",
            "Target Tokens: [2, 6, 7]\n",
            "Target Tensor: tensor([[2, 6, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc354d15"
      },
      "source": [
        "### 10. Training Loop with Dummy Data and Visualization\n",
        "\n",
        "This section sets up a basic training process using the dummy data and visualizes the training loss.\n",
        "\n",
        "*   **Model Instantiation**: Creates an instance of the Transformer model with specified parameters.\n",
        "*   **Optimizer**: Defines the optimization algorithm (Adam) used to update model weights during training.\n",
        "*   **Loss Function**: Defines the criterion (Cross-Entropy Loss) used to measure the difference between the model's output and the target sequence.\n",
        "*   **Training Loop**: Iterates through a set number of epochs, performs forward and backward passes, and updates model weights to minimize the loss.\n",
        "*   **Loss Tracking and Plotting**: Records the loss value at the end of each epoch and uses Matplotlib to plot how the loss changes over time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "49aa002a",
        "outputId": "feb4a082-e13d-4ed2-e986-a8fadef84377"
      },
      "source": [
        "# Model parameters (example values)\n",
        "src_vocab_size = len(vocab)\n",
        "tgt_vocab_size = len(vocab)\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 6\n",
        "num_decoder_layers = 6\n",
        "d_ff = 2048\n",
        "dropout = 0.1\n",
        "\n",
        "# Instantiate the Transformer model\n",
        "model = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_encoder_layers, num_decoder_layers, d_ff, dropout)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word_to_idx['<PAD>']) # Ignore padding in loss calculation\n",
        "\n",
        "# Dummy training loop (minimal)\n",
        "num_epochs = 10\n",
        "train_losses = [] # List to store loss values\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Dummy forward pass\n",
        "    output = model(dummy_src_tensor, dummy_tgt_tensor[:, :-1])\n",
        "\n",
        "    # Reshape output and target for loss calculation\n",
        "    output = output.contiguous().view(-1, tgt_vocab_size)\n",
        "    target = dummy_tgt_tensor[:, 1:].contiguous().view(-1)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(output, target)\n",
        "    train_losses.append(loss.item()) # Store the loss\n",
        "\n",
        "    # Backpropagation and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"\\nTraining loop finished.\")\n",
        "\n",
        "# Plot the training loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, marker='o')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 3.4162\n",
            "Epoch [2/10], Loss: 16.2449\n",
            "Epoch [3/10], Loss: 51.9910\n",
            "Epoch [4/10], Loss: 44.1209\n",
            "Epoch [5/10], Loss: 16.1783\n",
            "Epoch [6/10], Loss: 0.5032\n",
            "Epoch [7/10], Loss: 0.0000\n",
            "Epoch [8/10], Loss: 0.0000\n",
            "Epoch [9/10], Loss: 0.0000\n",
            "Epoch [10/10], Loss: 0.0000\n",
            "\n",
            "Training loop finished.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAIjCAYAAADWYVDIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAcPpJREFUeJzt3Xl4lNXB/vF7ZpJM9kBCVnYS9h0UiIBaZVVBlNalWpf6q28VbJX27etSFVyrvlWrIlZrta1St7cgqCCIyiaLrBJA9j0kAUJ2kkxmnt8fWUxkCyGZMzP5fq4r12WeeSa5mTlg7jznOcdmWZYlAAAAAIAkyW46AAAAAAD4EkoSAAAAANRCSQIAAACAWihJAAAAAFALJQkAAAAAaqEkAQAAAEAtlCQAAAAAqIWSBAAAAAC1UJIAAAAAoBZKEgD4gdtuu00dOnRo0HOnTp0qm83WuIGAU3j77bdls9m0Zs0a01EA4LxQkgDgPNhstnp9fP3116ajGnHbbbcpMjLSdIyAUV1CTvexcuVK0xEBICAEmQ4AAP7sX//6V53P//nPf2rhwoUnHe/evft5fZ833nhDHo+nQc/94x//qPvvv/+8vj98y2OPPaaOHTuedDwtLc1AGgAIPJQkADgPN998c53PV65cqYULF550/MdKSkoUHh5e7+8THBzcoHySFBQUpKAg/rn3F8XFxYqIiDjjOWPHjtUFF1zgpUQA0Pww3Q4Amtill16qXr16ae3atbr44osVHh6uBx98UJL08ccf68orr1RKSoqcTqdSU1P1+OOPy+121/kaP74nae/evbLZbPrf//1fvf7660pNTZXT6dSFF16ob7/9ts5zT3VPks1m0+TJkzV79mz16tVLTqdTPXv21Pz580/K//XXX+uCCy5QaGioUlNT9de//rXR73P68MMPNXDgQIWFhalVq1a6+eabdejQoTrnZGVl6fbbb1ebNm3kdDqVnJysq6++Wnv37q05Z82aNRo9erRatWqlsLAwdezYUb/85S/rleHVV19Vz5495XQ6lZKSokmTJikvL6/m8cmTJysyMlIlJSUnPffGG29UUlJSnfdt3rx5Gj58uCIiIhQVFaUrr7xSmzdvrvO86umIu3bt0hVXXKGoqCjddNNN9cp7JrXHxwsvvKD27dsrLCxMl1xyiTIyMk46/8svv6zJ2qJFC1199dXaunXrSecdOnRId9xxR8147dixo+666y6Vl5fXOa+srExTpkxRfHy8IiIidM011+jIkSN1zjmf9woAmhq/WgQALzh27JjGjh2rG264QTfffLMSExMlVd5jEhkZqSlTpigyMlJffvmlHnnkERUUFOi5554769edOXOmCgsL9V//9V+y2Wx69tlnde2112r37t1nvfq0bNky/ec//9Hdd9+tqKgovfTSS5o4caL279+vuLg4SdL69es1ZswYJScna9q0aXK73XrssccUHx9//i9Klbffflu33367LrzwQj399NPKzs7WX/7yFy1fvlzr169XixYtJEkTJ07U5s2bdc8996hDhw7KycnRwoULtX///prPR40apfj4eN1///1q0aKF9u7dq//85z9nzTB16lRNmzZNI0aM0F133aVt27ZpxowZ+vbbb7V8+XIFBwfr+uuv1/Tp0/Xpp5/qZz/7Wc1zS0pKNHfuXN12221yOBySKqdh3nrrrRo9erSeeeYZlZSUaMaMGRo2bJjWr19fp/BWVFRo9OjRGjZsmP73f/+3XlcY8/PzdfTo0TrHbDZbzftW7Z///KcKCws1adIklZaW6i9/+Ysuu+wybdq0qWYMfvHFFxo7dqw6deqkqVOn6sSJE3r55Zc1dOhQrVu3riZrZmamBg0apLy8PN15553q1q2bDh06pI8++kglJSUKCQmp+b733HOPWrZsqUcffVR79+7Viy++qMmTJ+v999+XpPN6rwDAKywAQKOZNGmS9eN/Wi+55BJLkvXaa6+ddH5JSclJx/7rv/7LCg8Pt0pLS2uO3XrrrVb79u1rPt+zZ48lyYqLi7Nyc3Nrjn/88ceWJGvu3Lk1xx599NGTMkmyQkJCrJ07d9Yc27hxoyXJevnll2uOjRs3zgoPD7cOHTpUc2zHjh1WUFDQSV/zVG699VYrIiLitI+Xl5dbCQkJVq9evawTJ07UHP/kk08sSdYjjzxiWZZlHT9+3JJkPffcc6f9WrNmzbIkWd9+++1Zc9WWk5NjhYSEWKNGjbLcbnfN8VdeecWSZP3973+3LMuyPB6P1bp1a2vixIl1nv/BBx9YkqwlS5ZYlmVZhYWFVosWLaxf/epXdc7LysqyYmJi6hy/9dZbLUnW/fffX6+sb731liXplB9Op7PmvOrxERYWZh08eLDm+KpVqyxJ1n333VdzrF+/flZCQoJ17NixmmMbN2607Ha7dcstt9Qcu+WWWyy73X7K19fj8dTJN2LEiJpjlmVZ9913n+VwOKy8vDzLshr+XgGAtzDdDgC8wOl06vbbbz/peFhYWM1/FxYW6ujRoxo+fLhKSkr0/fffn/XrXn/99WrZsmXN58OHD5ck7d69+6zPHTFihFJTU2s+79Onj6Kjo2ue63a79cUXX2jChAlKSUmpOS8tLU1jx44969evjzVr1ignJ0d33323QkNDa45feeWV6tatmz799FNJla9TSEiIvv76ax0/fvyUX6v6itMnn3wil8tV7wxffPGFysvLde+998pu/+F/i7/61a8UHR1dk8Fms+lnP/uZPvvsMxUVFdWc9/7776t169YaNmyYJGnhwoXKy8vTjTfeqKNHj9Z8OBwODR48WF999dVJGe66665655Wk6dOna+HChXU+5s2bd9J5EyZMUOvWrWs+HzRokAYPHqzPPvtMknT48GFt2LBBt912m2JjY2vO69Onj0aOHFlznsfj0ezZszVu3LhT3gv146mXd955Z51jw4cPl9vt1r59+yQ1/L0CAG+hJAGAF7Ru3brOdKRqmzdv1jXXXKOYmBhFR0crPj6+ZtGH/Pz8s37ddu3a1fm8ujCdrkic6bnVz69+bk5Ojk6cOHHKFdMaaxW16h+au3btetJj3bp1q3nc6XTqmWee0bx585SYmKiLL75Yzz77rLKysmrOv+SSSzRx4kRNmzZNrVq10tVXX6233npLZWVlDcoQEhKiTp061TwuVZbSEydOaM6cOZKkoqIiffbZZ/rZz35WUwp27NghSbrssssUHx9f52PBggXKycmp832CgoLUpk2bs79YtQwaNEgjRoyo8/GTn/zkpPM6d+580rEuXbrU3Md1pte/e/fuOnr0qIqLi3XkyBEVFBSoV69e9cp3tnHZ0PcKALyFkgQAXlD7ilG1vLw8XXLJJdq4caMee+wxzZ07VwsXLtQzzzwjSfVa8rv6HpgfsyyrSZ9rwr333qvt27fr6aefVmhoqB5++GF1795d69evl1R5NeOjjz7SihUrNHnyZB06dEi//OUvNXDgwDpXfs7HkCFD1KFDB33wwQeSpLlz5+rEiRO6/vrra86pft/+9a9/nXS1Z+HChfr444/rfE2n01nnClYgONvY8sZ7BQDnI7D+VQYAP/L111/r2LFjevvtt/Xb3/5WV111lUaMGFFn+pxJCQkJCg0N1c6dO0967FTHGqJ9+/aSpG3btp302LZt22oer5aamqrf/e53WrBggTIyMlReXq4///nPdc4ZMmSInnzySa1Zs0bvvvuuNm/erPfee++cM5SXl2vPnj0nZbjuuus0f/58FRQU6P3331eHDh00ZMiQOhmlytfvx1d7RowYoUsvvfQsr0rjqb6qVdv27dtrFmM40+v//fffq1WrVoqIiFB8fLyio6NPuTLe+TjX9woAvIWSBACGVP+2vfaVm/Lycr366qumItXhcDg0YsQIzZ49W5mZmTXHd+7cecr7XxriggsuUEJCgl577bU6U63mzZunrVu36sorr5RUuYJcaWlpneempqYqKiqq5nnHjx8/6SpYv379JOmM07hGjBihkJAQvfTSS3We/+abbyo/P78mQ7Xrr79eZWVl+sc//qH58+fruuuuq/P46NGjFR0draeeeuqU99v8eCnspjR79uw6S6mvXr1aq1atqrmnLDk5Wf369dM//vGPOsudZ2RkaMGCBbriiiskSXa7XRMmTNDcuXO1Zs2ak77PuV59bOh7BQDewhLgAGDIRRddpJYtW+rWW2/Vb37zG9lsNv3rX//yqeluU6dO1YIFCzR06FDdddddcrvdeuWVV9SrVy9t2LChXl/D5XLpiSeeOOl4bGys7r77bj3zzDO6/fbbdckll+jGG2+sWQK8Q4cOuu+++yRVXv24/PLLdd1116lHjx4KCgrSrFmzlJ2drRtuuEGS9I9//EOvvvqqrrnmGqWmpqqwsFBvvPGGoqOja37YP5X4+Hg98MADmjZtmsaMGaPx48dr27ZtevXVV3XhhReetDHwgAEDlJaWpoceekhlZWV1ptpJUnR0tGbMmKFf/OIXGjBggG644QbFx8dr//79+vTTTzV06FC98sor9XrtTmfevHmnXNjjoosuUqdOnWo+T0tL07Bhw3TXXXeprKxML774ouLi4vSHP/yh5pznnntOY8eOVXp6uu64446aJcBjYmI0derUmvOeeuopLViwQJdcconuvPNOde/eXYcPH9aHH36oZcuW1SzGUB8Nfa8AwGuMrasHAAHodEuA9+zZ85TnL1++3BoyZIgVFhZmpaSkWH/4wx+szz//3JJkffXVVzXnnW4J8FMtiS3JevTRR2s+P90S4JMmTTrpue3bt7duvfXWOscWLVpk9e/f3woJCbFSU1Otv/3tb9bvfvc7KzQ09DSvwg+ql7g+1UdqamrNee+//77Vv39/y+l0WrGxsdZNN91UZ+nqo0ePWpMmTbK6detmRUREWDExMdbgwYOtDz74oOacdevWWTfeeKPVrl07y+l0WgkJCdZVV11lrVmz5qw5Latyye9u3bpZwcHBVmJionXXXXdZx48fP+W5Dz30kCXJSktLO+3X++qrr6zRo0dbMTExVmhoqJWammrddtttdfKcbYn0HzvTEuCSrLfeesuyrLrj489//rPVtm1by+l0WsOHD7c2btx40tf94osvrKFDh1phYWFWdHS0NW7cOGvLli0nnbdv3z7rlltuseLj4y2n02l16tTJmjRpklVWVlYn34+X9v7qq6/qjOnzfa8AoKnZLMuHfmUJAPALEyZM0ObNm095zwvM27t3rzp27KjnnntOv//9703HAQC/wz1JAIAzOnHiRJ3Pd+zYoc8++8yrCxAAAOBN3JMEADijTp066bbbbqvZM2jGjBkKCQmpc18LAACBhJIEADijMWPG6N///reysrLkdDqVnp6up5566pQblQIAEAi4JwkAAAAAauGeJAAAAACohZIEAAAAALUE/D1JHo9HmZmZioqKks1mMx0HAAAAgCGWZamwsFApKSmy209/vSjgS1JmZqbatm1rOgYAAAAAH3HgwAG1adPmtI8HfEmKioqSVPlCREdHG06DhnC5XFqwYIFGjRql4OBg03HQDDDm4G2MOXgT4w3e5ktjrqCgQG3btq3pCKcT8CWpeopddHQ0JclPuVwuhYeHKzo62vhfLDQPjDl4G2MO3sR4g7f54pg72204LNwAAAAAALVQkgAAAACgFkoSAAAAANRCSQIAAACAWihJAAAAAFALJQkAAAAAaqEkAQAAAEAtlCQAAAAAqIWSBAAAAAC1UJIAAAAAoBZKEgAAAADUQkkCAAAAgFooSQAAAABQS5DpAACahttjafWeXOUUliohKlSDOsbKYbeZjgUAAODzKElAAJqfcVjT5m7R4fzSmmPJMaF6dFwPjemVbDAZAACA72O6HRBg5mcc1l3vrKtTkCQpK79Ud72zTvMzDhtKBgAA4B8oSUAAcXssTZu7RdYpHqs+Nm3uFrk9pzoDAAAAEiUJCCir9+SedAWpNkvS4fxSrd6T671QAAAAfoaSBASQnMLTF6SGnAcAANAcUZKAAJIQFdqo5wEAADRHlCQggAzqGKvkmDMXIGeQXd2So7yUCAAAwP9QkoAA4rDb9Oi4Hmc8p6zCo4mvfqOdOUVeSgUAAOBfKElAgBnTK1n92sacdDw5JlQPju2mlJhQ7T5arGumL9eX32cbSAgAAODb2EwWCDAVbo925RRLkp6Y0EtRoUFKiArVoI6xcthtunZgG939zjqt3purO/6xRv89uqvuuiRVNpvNcHIAAADfwJUkIMBsPJivwrIKxYQF68ZB7XR1v9ZKT42Tw15ZglpFOvXO/xusmwa3k2VJz87fpnv+vV4nyt2GkwMAAPgGShIQYJbuOCJJGpbWqqYY/VhIkF1PXtNbT0zopSC7TZ98d1g/fe0bHTxe4s2oAAAAPomSBASYZTuOSpKGdW511nNvHtJeM381RHERIdqcWaDxryzXqt3HmjoiAACAT6MkAQGksNSl9QfyJFVeSaqPQR1jNeeeYeqZEq3c4nLd9LdV+tfKfU2YEgAAwLdRkoAAsmLXMbk9ljq2ilDb2PB6P691izB99OuLNK5viio8lh6enaEHZ21SeYWnCdMCAAD4JkoSEECW7ayaalfPq0i1hYU49NIN/XT/2G6y2aSZq/brpr+t1JHCssaOCQAA4NOMlqSpU6fKZrPV+ejWrVvN46WlpZo0aZLi4uIUGRmpiRMnKjubfV2A01ladT/S8Hrcj3QqNptNv74kVX+/9UJFhQbp273HNf6VZdp0ML8xYwIAAPg041eSevbsqcOHD9d8LFu2rOax++67T3PnztWHH36oxYsXKzMzU9dee63BtIDvOni8RHuOFstht2lIatx5fa2fdEvQ7ElD1Sk+QofzS/XT177RxxsONVJSAAAA32Z8M9mgoCAlJSWddDw/P19vvvmmZs6cqcsuu0yS9NZbb6l79+5auXKlhgwZ4u2ogE+rXtWuf9sWig4NPu+vlxofqdmThuq3/16vr7Yd0W/f26Athwv0h9HdTru0OAAAQCAwXpJ27NihlJQUhYaGKj09XU8//bTatWuntWvXyuVyacSIETXnduvWTe3atdOKFStOW5LKyspUVvbDPRQFBQWSJJfLJZfL1bR/GDSJ6veN9+/MFm/LkSRd1Cm20V6rMIc04+f99OKinXptyR79dfFubc3M1ws/66PosPMvYr6KMQdvY8zBmxhv8DZfGnP1zWCzLMtq4iynNW/ePBUVFalr1646fPiwpk2bpkOHDikjI0Nz587V7bffXqfwSNKgQYP0k5/8RM8888wpv+bUqVM1bdq0k47PnDlT4eH1X+0L8CceS3pojUMlFTbd26tCHaMa/3usO2rTzF12uTw2xYda+n9d3UrirxQAAPAjJSUl+vnPf678/HxFR0ef9jyjJenH8vLy1L59ez3//PMKCwtrUEk61ZWktm3b6ujRo2d8IeC7XC6XFi5cqJEjRyo4OHCvXpyP7w7ma+JfVynSGaRvH7hUQY6mud1wc2aB7p65QZn5pYpwOvT8z/rosq7xTfK9TGLMwdsYc/Amxhu8zZfGXEFBgVq1anXWkmR8ul1tLVq0UJcuXbRz506NHDlS5eXlysvLU4sWLWrOyc7OPuU9TNWcTqecTudJx4ODg42/KTg/vIent3JvniTpotQ4hYWePP4bS7/2cZpzzzDd/c46rd6bq1+/u16/H9VVd1+aKpst8O5TYszB2xhz8CbGG7zNF8Zcfb+/8dXtaisqKtKuXbuUnJysgQMHKjg4WIsWLap5fNu2bdq/f7/S09MNpgR8z9IdRyRJw7s0/VWdVpFOvfP/BuvmIe1kWdJzn2/T5H+vV0l5RZN/bwAAAG8wWpJ+//vfa/Hixdq7d6+++eYbXXPNNXI4HLrxxhsVExOjO+64Q1OmTNFXX32ltWvX6vbbb1d6ejor2wG1FJdVaO2+45Kk4Q3YRLYhQoLsemJCbz11TW8FO2z69LvD+umMFTp4vMQr3x8AAKApGZ1ud/DgQd144406duyY4uPjNWzYMK1cuVLx8ZW/DX/hhRdkt9s1ceJElZWVafTo0Xr11VdNRgZ8zuo9uXK5LbVpGab2cd5dSeHng9upc2Kk7npnrbYcLtD4V5br1ZsGaEin89unCQAAwCSjJem999474+OhoaGaPn26pk+f7qVEgP9ZUj3VrnO8kfuCLuwQqzmTh+nOf61RxqEC3fy3VXp0XA/dPKR9QN6nBAAAAp9P3ZME4NxVbyI7vLN3ptqdSkqLMH34Xxfp6n4pqvBYevjjzXpw1iaVV3iMZQIAAGgoShLgx7LyS7Ujp0h2W+XKdiaFhTj04vX99MDYbrLZpH+vPqCfv7FSRwrLzv5kAAAAH0JJAvxY9ap2vdu0UIvwEMNpJJvNpv+6JFV/v+1CRYUGac2+4xr/yjJ9dzDPdDQAAIB6oyQBfmzZzqqpdl5a1a6+ftI1QR9PGqrU+Agdzi/Vz15bodnrD5mOBQAAUC+UJMBPeTyWT9yPdDqd4iM1a9JQXdYtQWUVHt37/gY99dlWuT2W6WgAAABnREkC/NTWrAIdKy5XeIhD/du1NB3nlKJDg/XGLRdo0k9SJUmvL9mt29/+VvklLsPJAAAATo+SBPip6qtI6Z3iFBLku3+VHXab/nt0N718Y3+FBtu1ZPsRXT19mXbmFJqOBgAAcEq++5MVgDNaWlWShvngVLtTGdc3Rf9310Vq3SJMe4+VaML0b/TFlmzTsQAAAE5CSQL8UKnLrdV7cyX55v1Ip9MzJUZzJg/V4I6xKiqr0K/+tUavfLlDlsV9SgAAwHdQkgA/tHpPrsorPEqOCVVqfKTpOOckLtKpd/7fYN2S3l6WJf3vgu2aPHO9SsorTEcDAACQREkC/FL10t/D0lrJZrMZTnPugh12PXZ1Lz19bW8FO2z6dNNhXfvqNzqQW2I6GgAAACUJ8EfV9yMN7xJvOMn5uXFQO/37V0PUKjJE32cVavwry7Ri1zHTsQAAQDNHSQL8zJHCMm09XCBJGpoaZzjN+bugQ6zmTB6m3q1jdLzEpZvfXKV/fLOX+5QAAIAxlCTAzyyvmmrXMyVacZFOw2kaR0qLMH3463RN6Jcit8fSo3M26/7/26SyCrfpaAAAoBmiJAF+ZsmOI5Kk4Z39e6rdj4UGO/TC9f304BXdZLdJ7685oBtfX6mcwlLT0QAAQDNDSQL8iGVZNZvI+tPS3/Vls9l058Wp+vttFyoqNEjr9udp/MvLtfFAnuloAACgGaEkAX5kR06RcgrLFBps18D2LU3HaTKXdk3Qx5OGKjU+QlkFpfrZX1foP+sOmo4FAACaCUoS4EeWbK+cajeoY5xCgx2G0zStTvGRmj1pqEZ0T1B5hUdTPtioJz/dogq3x3Q0AAAQ4ChJgB+p3h9peFrgTbU7lajQYL3+iwt0z2VpkqQ3lu7R7W9/q/wSl+FkAAAgkFGSAD9RVuHWyt2VewgN79I8SpIk2e02/W5UV03/+QCFBTu0dMdRXT19mXZkF5qOBgAAAhQlCfATa/cdV6nLo/gop7omRpmO43VX9knW/911kVq3CNPeYyWaMH25Fm7JNh0LAAAEIEoS4CdqVrVLayWbzWY4jRk9UqI1Z/JQDekUq+Jyt371zzV6adEOeTxsPAsAABoPJQnwE0urStKwAFz6+1zERTr1rzsG69b09pKk5xdu16SZ61RcVmE4GQAACBSUJMAP5BaXKyMzX5I0rJks2nAmwQ67pl3dS3+6treCHTbNy8jSxBnf6EBuieloAAAgAFCSAD+wfOdRWZbULSlKCdGhpuP4jBsGtdN7dw5Rq0invs8q1PhXlumbqhUAAQAAGoqSBPiB6vuRuIp0soHtYzX3nqHq0yZGx0tc+sXfV+vt5XtkWdynBAAAGoaSBPg4y7J+2B+pS7zhNL4pOSZMH/xXuq7p31puj6Wpc7fof/7vO5VVuE1HAwAAfoiSBPi43UeLdSjvhEIcdg3qEGs6js8KDXbo+ev66qErustukz5Yc1A3vL5SOQWlpqMBAAA/Q0kCfFz1VLsLOrRUWIjDcBrfZrPZ9KuLO+nt2wcpOjRI6/fnadwry7ThQJ7paAAAwI9QkgAft3THEUnS8M5Mtauvi7vEa87kYUpLiFR2QZmu++sK/d/ag6ZjAQAAP0FJAnyYy+3Ryt25kqThzXx/pHPVoVWEZt19kUZ0T1R5hUe/+3CjHv9kiyrcHtPRAACAj6MkAT5sw4E8FZVVKDYiRD2So03H8TtRocF6/RcD9ZvL0iRJby7bo9ve+lZ5JeWGkwEAAF9GSQJ82NLtlVPthqa1kt1uM5zGP9ntNk0Z1VWv3jRAYcEOLdt5VONfWa7t2YWmowEAAB9FSQJ82NLqpb/ZH+m8XdE7Wf+5+yK1aRmm/bklumb6cn2+Oct0LAAA4IMoSYCPyi9xaWPVqmzDuB+pUXRPjtacycOU3ilOxeVu/de/1uovX+yQx8PGswAA4AeUJMBHrdh9VB5LSo2PUEqLMNNxAkZsRIj+eccg3XZRB0nSC19s193vrlNxWYUkye2xtGpPrtYetWnVnly5KVAAADQ7QaYDADi1pVX7I7H0d+MLdtg1dXxPdU+O0h9nZ2j+5iztebVYNw9pr1e/3qnD+aWSHPrnjjVKjgnVo+N6aEyvZNOxAQCAl3AlCfBRP5Qkpto1lesvbKf37kxXfJRT27IL9fDHGVUF6QdZ+aW66511mp9x2FBKAADgbZQkwAftO1as/bklCrLbNLhTnOk4AW1g+5aaffdQBTtOvXpg9WS7aXO3MPUOAIBmgpIE+KDqq0gD2rdUpJNZsU1tf26JXO7TFyBL0uH8Uq3ek+u9UAAAwBhKEuCDlu1g6W9vyiksPftJ53AeAADwb5QkwMdUuD36ZldVSerCog3ekBAV2qjnAQAA/0ZJAnzMd4fyVVBaoZiwYPVuHWM6TrMwqGOskmNCdeq7kiSbpOSYUA3qGOvNWAAAwBBKEuBjqqfaXZQaJ4f9dD+2ozE57DY9Oq6HJJ22KD06rgfvBwAAzQQlCfAxS3cckcT+SN42pleyZtw8QEkxdafURTgdmnHzAPZJAgCgGWHZLMCHFJVVaP3+PEnsj2TCmF7JGtkjSSt25uiNz1ZrcZZdMaHBGtUjyXQ0AADgRVxJAnzIyl3HVOGx1CEuXG1jw03HaZYcdpsGd4zVVe08inA6lJlfqnX7j5uOBQAAvIiSBPiQ6ql2w7iKZFyIQxrZLUGSNGdjpuE0AADAmyhJgA9ZurNy0YZhadyP5Auu6lM5ze6zTYdV4fYYTgMAALyFkgT4iEN5J7T7SLEcdpvSU+NMx4EqVxhsGR6so0XlWrH7mOk4AADASyhJgI9YVjXVrm+bGMWEBRtOA0kKdtg1tnflqnZzNjDlDgCA5oKSBPiIpVX7I7H0t28Z3zdFkjR/c5bKKtyG0wAAAG+gJAE+wOOxtHxndUli0QZfMqhDrJKiQ1VYWqHF246YjgMAALyAkgT4gM2ZBTpe4lKkM0h927YwHQe12O02XdWnasodq9wBANAsUJIAH7Ck6n6k9NQ4BTv4a+lrxvernHL3xdZsFZdVGE4DAACaGj+NAT5g2Q6m2vmy3q1j1D4uXKUuj77Ymm06DgAAaGKUJMCwkvIKrd13XBKLNvgqm81Ws4ADq9wBABD4KEmAYav25Krc7VHrFmHqEBduOg5Oo7okLdlxRHkl5YbTAACApkRJAgyrPdXOZrMZToPT6ZwYpW5JUXK5Lc3PyDIdBwAANCFKEmDY0qpFG5hq5/uqF3BglTsAAAIbJQkwKLugVNuzi2SzSRelxpmOg7MY16eyJK3YfUw5BaWG0wAAgKZCSQIMqp5q16d1jFpGhBhOg7NpGxuu/u1ayLKkT747bDoOAABoIpQkwKDqqXbDWPrbb1Qv4DD3O6bcAQAQqChJgCEej6VlO49JkoalcT+Sv7iyT7LsNmn9/jwdyC0xHQcAADQBShJgyPdZhTpaVKbwEIcGtG9hOg7qKSEqVEM6Vd4/xgIOAAAEJkoSYMiynZVT7QZ3jJUzyGE4Dc5FzZQ7ShIAAAGJkgQYsrRmfySm2vmbsb2SFeyw6fusQm3PLjQdBwAANDJKEmBAqcut1XtyJVVuIgv/EhMerEu6VJZbriYBABB4KEmAAWv2HldZhUeJ0U6lJUSajoMGGNf3h41lLcsynAYAADQmShJgQPXS38M7x8tmsxlOg4YY0T1RocF27TtWou8O5puOAwAAGpHPlKQ//elPstlsuvfee2uOlZaWatKkSYqLi1NkZKQmTpyo7OxscyGBRvLD/UhMtfNXEc4gjeieKIlV7gAACDQ+UZK+/fZb/fWvf1WfPn3qHL/vvvs0d+5cffjhh1q8eLEyMzN17bXXGkoJNI6jRWXacrhAkjQ0jZLkz6pXufvku0x5PEy5AwAgUBgvSUVFRbrpppv0xhtvqGXLljXH8/Pz9eabb+r555/XZZddpoEDB+qtt97SN998o5UrVxpMDJyf5TsrryL1SI5Wq0in4TQ4H5d0jVdUaJCyC8q0em+u6TgAAKCRBJkOMGnSJF155ZUaMWKEnnjiiZrja9eulcvl0ogRI2qOdevWTe3atdOKFSs0ZMiQU369srIylZWV1XxeUFD5G3uXyyWXy9VEfwo0per3LVDev8XbciRJF6XGBsyfKdDUd8zZJY3qkaD/W5ep2esPamDbaC+kQyAKtH/n4NsYb/A2Xxpz9c1gtCS99957Wrdunb799tuTHsvKylJISIhatGhR53hiYqKysrJO+zWffvppTZs27aTjCxYsUHh4+HlnhjkLFy40HeG8WZa0KMMhyaaQY7v02Wc7TUfCGdRnzCWcsElyaO76Axpk3yuH8evz8GeB8O8c/AfjDd7mC2OupKSkXucZK0kHDhzQb3/7Wy1cuFChoaGN9nUfeOABTZkypebzgoICtW3bVqNGjVJ0NL/l9Ucul0sLFy7UyJEjFRwcbDrOedmRU6T8ld/IGWTX3T+7XM5gh+lIOIVzGXOj3B598NwSHSsuV3SXC2v2TwLORSD9Owffx3iDt/nSmKueZXY2xkrS2rVrlZOTowEDBtQcc7vdWrJkiV555RV9/vnnKi8vV15eXp2rSdnZ2UpKSjrt13U6nXI6T77PIzg42PibgvMTCO/hyj15kqRBHWMVGd54vxxA06jPmAsOlq7qk6x/rNinzzJyNKJnipfSIRAFwr9z8B+MN3ibL4y5+n5/YxNDLr/8cm3atEkbNmyo+bjgggt000031fx3cHCwFi1aVPOcbdu2af/+/UpPTzcVGzgvP+yPxKp2gWR8v8pi9PnmLJW63IbTAACA82XsSlJUVJR69epV51hERITi4uJqjt9xxx2aMmWKYmNjFR0drXvuuUfp6emnXbQB8GVlFW6t3F25AtqwNKZkBZL+bVuqdYswHco7oS+/z9EVvZNNRwIAAOfBp28xfuGFF3TVVVdp4sSJuvjii5WUlKT//Oc/pmMBDbJuX55OuNxqFelUt6Qo03HQiOx2m67qW1mM5mxgY1kAAPyd8SXAa/v666/rfB4aGqrp06dr+vTpZgIBjWjZzsqpdsPS4mS32wynQWMb3zdFf128W19uy1FhqUtRoczzBwDAX/n0lSQgkCzbUbmJ7PDOTLULRD2So5UaH6HyCo8WbM42HQcAAJwHShLgBceLy/XdoXxJ0jAWbQhINptN4/u2liTN2ciUOwAA/BklCfCCb3Ydk2VJXRIjlRjN0t+BalzVfUnLdh7VsaIyw2kAAEBDUZIAL/hh6W+m2gWyTvGR6tU6Wm6PpXkZWabjAACABqIkAU3Msiwtrbofial2gW9838o9k5hyBwCA/6IkAU1s77ESHco7oRCHXYM7xpqOgyZ2VZ/KkvTt3lwdzj9hOA0AAGgIShLQxKqn2g1s31LhIT616j6aQEqLMF3YoaUsS/pk42HTcQAAQANQkoAmxlS75ocpdwAA+DdKEtCEXG6PVuw6Jkm6mEUbmo0reifLYbdp06F87TlabDoOAAA4R5QkoAltPJCnorIKtQwPVs+UaNNx4CVxkU4NTau8cjiXq0kAAPgdShLQhKqn2g1NayW73WY4Dbyp9pQ7y7IMpwEAAOeCkgQ0oR/2R+J+pOZmVM9EhQTZtTOnSFsPF5qOAwAAzgElCWgi+Sdc2ngwX5I0jPuRmp3o0GD9pGvl+84CDgAA+BdKEtBEVuw6JrfHUqf4CLVuEWY6DgwY37e1pMr7kphyBwCA/6AkAU1k2c6qqXZpTLVrri7rlqCIEIcO5Z3Quv15puMAAIB6oiQBTWRZ1aINw5lq12yFhTg0skeiJFa5AwDAn1CSgCZwILdEe4+VKMhu05DUONNxYND4fpWr3H3y3WFVuD2G0wAAgPqgJAFNoHrp7/7tWijSGWQ4DUwalhavFuHBOlpUplV7ck3HAQAA9UBJAprAD0t/M9WuuQsJsmtsr2RJ0pwNTLkDAMAfUJKARub2WPpm1zFJ0jD2R4J+2Fh2XsZhlVW4DacBAABnQ0kCGtmmQ/nKP+FSdGiQ+rSOMR0HPmBQx1glRDlVUFqhJduPmo4DAADOgpIENLKl2yun2l2U2kpBDv6KQXLYbbqqT+XVJDaWBQDA9/ETHNDIlu6svFLAVDvUVr3K3RdbslVSXmE4DQAAOBNKEtCIisoqtG7fcUnSxSzagFr6tolR+7hwnXC59cXWHNNxAADAGVCSgEa0avcxVXgstYsNV7u4cNNx4ENsNpvGVU+5Y5U7AAB8GiUJaETV+yMNZ6odTmFc1Sp3i7fnKL/EZTgNAAA4HUoS0Ih+2B+JkoSTdU2KUtfEKLnclj7fnGU6DgAAOA1KEtBIMvNOaNeRYtltUnoqJQmnVr2AA6vcAQDguyhJQCNZVjXVrm/bFooJCzacBr6q+r6kb3YdVU5hqeE0AADgVChJQCOpXvp7eBpXkXB67eLC1bdtC3ks6bPvDpuOAwAAToGSBDQCj8fS8uqS1IWlv3Fm4/sy5Q4AAF9GSQIawZbDBcotLlekM0j92rYwHQc+7qo+ybLZpHX783Qgt8R0HAAA8COUJKARVC/9PaRTrIId/LXCmSVGh2pIxzhJ0idMuQMAwOfw0xzQCH5Y+pupdqgfVrkDAMB3UZKA83Si3K01e49LkoaxPxLqaUzPJAXZbdp6uEA7cwpNxwEAALVQkoDztHpvrsrdHrVuEaZOrSJMx4GfaBkRoourFvmYs5EpdwAA+BJKEnCelm6vnGo3LK2VbDab4TTwJ9Wr3M3dmCnLsgynAQAA1ShJwHlaVrX0N1PtcK5G9khUaLBde44WK+NQgek4AACgCiUJOA85BaX6PqtQNps0lE1kcY4inEG6vFuiJGnOxkOG0wAAgGqUJOA8VF9F6pUSo9iIEMNp4I/GVU25++S7w/J4mHIHAIAvoCQB52FZ1f5Iw5lqhwa6tGu8opxBOpxfqjX7jpuOAwAAREkCGsyyLC3lfiScp9Bgh0b3SpLElDsAAHwFJQlooG3ZhTpSWKawYIcGtm9pOg78WPUqd59typLL7TGcBgAAUJKABqqeaje4U6ycQQ7DaeDPLkqNU1xEiHKLy7W86uokAAAwh5IENNCSqpI0jFXtcJ6CHHZd0TtZkjRnY6bhNAAAgJIENECpy63Ve45Jki7uEm84DQLB+H6VU+4WbM5WqcttOA0AAM0bJQlogLX7jqvU5VFitFOdEyJNx0EAGNiupVJiQlVUVqGvt+WYjgMAQLNGSQIaYGnVVLuhaa1ks9kMp0EgsNttNXsmMeUOAACzKElAAyzbeUSSdHFnptqh8VSXpEVbc1RY6jKcBgCA5ouSBJyjY0VlyjhUIKnyShLQWHqmRKtTqwiVVXj0xdZs03EAAGi2KEnAOVq+q3LBhu7J0YqPchpOg0Bis9WacreBKXcAAJhCSQLO0dLtlVPthnfmKhIaX3VJWrrjqI4XlxtOAwBA80RJAs6BZVlatpP9kdB00hIi1SM5WhUeS59lHDYdBwCAZomSBJyDXUeKdTi/VCFBdg3qGGs6DgJU9Z5JTLkDAMAMShJwDpbuqJxqN6hDrEKDHYbTIFBVT7lbvTdXWfmlhtMAAND8UJKAc7Csan8k7kdCU2rdIkwXtG8py5I++Y6rSQAAeBslCain8gqPVuyuXNluGCUJTax6yt1cNpYFAMDrKElAPa3ff1wl5W7FRYSoe1K06TgIcGN7JctukzYezNfeo8Wm4wAA0KxQkoB6qlnVrnMr2e02w2kQ6OKjnDWbFTPlDgAA76IkAfW0ZAdLf8O7ajaWZcodAABeRUkC6iGvpFybDuZJkoZ3jjcbBs3G6J5JCnHYtT27SN9nFZiOAwBAs0FJAurhm13H5LGkzgmRSooJNR0HzURMWLAu6VpZytkzCQAA76EkAfWwdMcP9yMB3jS+asrd3O8yZVmW4TQAADQPlCTgLCzLqtlE9mKm2sHLRnRPVHiIQwdyT2jDgTzTcQAAaBYoScBZ7DtWooPHTyjYYdPgTrGm46CZCQtxaGSPREks4AAAgLdQkoCzWFq19PfA9i0VHhJkOA2ao+opd598d1huD1PuAABoapQk4CyWbq+caseqdjBleOd4xYQF60hhmVbtPmY6DgAAAY+SBJxBhdujFbsqfyhlfySYEhJk19heSZKYcgcAgDdQkoAz2HgwX4VlFWoRHqxerWNMx0EzVj3lbl5GlsorPIbTAAAQ2IyWpBkzZqhPnz6Kjo5WdHS00tPTNW/evJrHS0tLNWnSJMXFxSkyMlITJ05Udna2wcRobqpXtRua2koOu81wGjRngzvFKSHKqfwTrppxCQAAmobRktSmTRv96U9/0tq1a7VmzRpddtlluvrqq7V582ZJ0n333ae5c+fqww8/1OLFi5WZmalrr73WZGQ0M8uq9kcazv5IMMxht+nKPsmSmHIHAEBTM7pU17hx4+p8/uSTT2rGjBlauXKl2rRpozfffFMzZ87UZZddJkl666231L17d61cuVJDhgwxERnNSEGpS+ur9qVhE1n4gnF9U/TW8r1auCVbJ8rdCgtxmI4EAEBA8pn1jN1utz788EMVFxcrPT1da9eulcvl0ogRI2rO6datm9q1a6cVK1actiSVlZWprKys5vOCggJJksvlksvlato/BJpE9fvm7fdv+fYcuT2WOsSFKzEymPHTjJgac2fTKylCbVqG6eDxE1qQkakreieZjoRG4qtjDoGJ8QZv86UxV98MxkvSpk2blJ6ertLSUkVGRmrWrFnq0aOHNmzYoJCQELVo0aLO+YmJicrKyjrt13v66ac1bdq0k44vWLBA4eHhjR0fXrRw4UKvfr+Pdtsl2dU2qEifffaZV783fIO3x1x9dAu36+Bxu/62cIN0gAUcAo0vjjkELsYbvM0XxlxJSUm9zjNekrp27aoNGzYoPz9fH330kW699VYtXry4wV/vgQce0JQpU2o+LygoUNu2bTVq1ChFR0c3RmR4mcvl0sKFCzVy5EgFBwd77fu+8OIySSX6+eUDNKJ7gte+L8wzNebqIzWrUF9MX6HvCxwa9pPLFR3mW/nQML485hB4GG/wNl8ac9WzzM7GeEkKCQlRWlqaJGngwIH69ttv9Ze//EXXX3+9ysvLlZeXV+dqUnZ2tpKSTj/FxOl0yul0nnQ8ODjY+JuC8+PN9/BAbon2HiuRw27TsC4JjJ1myhf/3ejZpqU6J0RqR06RFm0/pusuaGs6EhqRL445BC7GG7zNF8Zcfb+/z+2T5PF4VFZWpoEDByo4OFiLFi2qeWzbtm3av3+/0tPTDSZEc7BsZ+Wqdv3btlBUKP8Dge+w2Ww1eybNZZU7AACahNErSQ888IDGjh2rdu3aqbCwUDNnztTXX3+tzz//XDExMbrjjjs0ZcoUxcbGKjo6Wvfcc4/S09NZ2Q5Nrnrpb1a1gy8a1zdFf164Xct3HtXRojK1ijz56jkAAGg4oyUpJydHt9xyiw4fPqyYmBj16dNHn3/+uUaOHClJeuGFF2S32zVx4kSVlZVp9OjRevXVV01GRjPg9lhavqt6f6R4w2mAk3VoFaG+bWK08WC+Ptt0WLekdzAdCQCAgGK0JL355ptnfDw0NFTTp0/X9OnTvZQIkDIO5SuvxKWo0CD1bRNjOg5wSuP6pmjjwXzN2ZBJSQIAoJH53D1JgGnV9yNdlBqnIAd/ReCbruqTIptNWrPvuA7lnTAdBwCAgMJPgMCPLNl+RJI0jKl28GFJMaEa1CFWkvQJCzgAANCoKElALcVlFVq3/7gkaXgaizbAt43vV7nK3RxKEgAAjYqSBNSyek+uXG5LbWPD1D4u3HQc4IzG9kpWkN2mzZkF2nWkyHQcAAACBiUJqGXJjqqpdmnxstlshtMAZxYbEVKzTP2cDVxNAgCgsVCSgFqq90e6mP2R4CdqbyxrWZbhNAAABAZKElDlcP4J7cgpkt0mXZRKSYJ/GNUzSc4gu3YfLdbmzALTcQAACAiUJKBK9VWk3m1aKCY82HAaoH4inUG6vHuCpMqrSQAA4PxRkoAq1fsjMdUO/qb2lDuPhyl3AACcL0oSIMnjsWquJA1j6W/4mUu7JijSGaTM/FKtrVrCHgAANBwlCZC0NatAx4rLFRHiUP92LU3HAc5JaLBDo3omSmLKHQAAjYGSBEhaWnUVaUinOIUE8dcC/qd6yt1nmw6rwu0xnAYAAP/GT4OAfli0YRj3I8FPDU1rpdiIEB0tKtc3u46ZjgMAgF+jJKHZK3W5tXpvriRpeOd4w2mAhgl22HVF7yRJ0hym3AEAcF4aVJIOHDiggwcP1ny+evVq3XvvvXr99dcbLRjgLav35Kq8wqPkmFClxkeYjgM02Lg+lVPuPs/IUqnLbTgNAAD+q0El6ec//7m++uorSVJWVpZGjhyp1atX66GHHtJjjz3WqAGBpla99Pfwzq1ks9kMpwEa7sIOsUqOCVVhWYUWbz9iOg4AAH6rQSUpIyNDgwYNkiR98MEH6tWrl7755hu9++67evvttxszH9DkllT9MDmMqXbwc3a7TVf1SZbElDsAAM5Hg0qSy+WS0+mUJH3xxRcaP368JKlbt246fPhw46UDmtiRwjJ9n1UoSRqaGmc4DXD+xvdtLUlatDVbxWUVhtMAAOCfGlSSevbsqddee01Lly7VwoULNWbMGElSZmam4uL4QRP+Y3nVVLteraMVF+k0nAY4f71aR6tDXLhKXR4t3JJtOg4AAH6pQSXpmWee0V//+lddeumluvHGG9W3b19J0pw5c2qm4QH+YMmOqql2aUy1Q2Cw2Ww1eyYx5Q4AgIYJasiTLr30Uh09elQFBQVq2bJlzfE777xT4eHhjRYOaEqWZdXsj3Qx+yMhgIzvl6KXvtypJduPKK+kXC3CQ0xHAgDArzToStKJEydUVlZWU5D27dunF198Udu2bVNCQkKjBgSayvbsIuUUlik02K6BHVqe/QmAn0hLiFL35GhVeCzNy8gyHQcAAL/ToJJ09dVX65///KckKS8vT4MHD9af//xnTZgwQTNmzGjUgEBTWVo11W5Qxzg5gxyG0wCNq2bK3Qam3AEAcK4aVJLWrVun4cOHS5I++ugjJSYmat++ffrnP/+pl156qVEDAk2len8kptohEFUvBb5yzzFlF5QaTgMAgH9pUEkqKSlRVFSUJGnBggW69tprZbfbNWTIEO3bt69RAwJNoazCrZW7j0mShlGSEIDaxoZrQLsWsizp0+/YmgEAgHPRoJKUlpam2bNn68CBA/r88881atQoSVJOTo6io6MbNSDQFNbuO65Sl0fxUU51TYwyHQdoEqxyBwBAwzSoJD3yyCP6/e9/rw4dOmjQoEFKT0+XVHlVqX///o0aEGgKS6tWtRue1ko2m81wGqBpXNEnWXabtOFAnvYfKzEdBwAAv9GgkvTTn/5U+/fv15o1a/T555/XHL/88sv1wgsvNFo4oKlUL/3NVDsEsoSoUKWnVm7wPfc7riYBAFBfDSpJkpSUlKT+/fsrMzNTBw8elCQNGjRI3bp1a7RwQFPILS5XRma+JGlYGiUJgY1V7gAAOHcNKkkej0ePPfaYYmJi1L59e7Vv314tWrTQ448/Lo/H09gZgUa1fOdRWZbULSlKCdGhpuMATWpMz2QFO2zall2obVmFpuMAAOAXghrypIceekhvvvmm/vSnP2no0KGSpGXLlmnq1KkqLS3Vk08+2aghgcZUPdVuOFPt0AzEhAfrki4J+mJrtuZuzFTXpK6mIwEA4PMaVJL+8Y9/6G9/+5vGjx9fc6xPnz5q3bq17r77bkoSfJZlWTWbyA7rHG84DeAd4/ul6Iut2ZqzMVO/G9WFxUoAADiLBk23y83NPeW9R926dVNubu55hwKayu6jxcrML1WIw65BHWJNxwG8YkT3BIUFO7Q/t0QbD+abjgMAgM9rUEnq27evXnnllZOOv/LKK+rTp895hwKaSvVUuws7tlRYiMNwGsA7wkOCNKJHoiRpLnsmAQBwVg2abvfss8/qyiuv1BdffFGzR9KKFSt04MABffbZZ40aEGhMNVPt0phqh+ZlfN8Uzd2YqU++y9SDV3SXw86UOwAATqdBV5IuueQSbd++Xddcc43y8vKUl5ena6+9Vps3b9a//vWvxs4INAqX26MVu45JYtEGND8Xd2ml6NAgZReUafUepkUDAHAmDbqSJEkpKSknLdCwceNGvfnmm3r99dfPOxjQ2Nbvz1NxuVuxESHqkRxtOg7gVc4gh8b2Stb7aw5ozsbMmk1mAQDAyRq8mSzgb5ZVTbUbmtZKdqYaoRkaV7Wx7LyMwyqvYE87AABOh5KEZmPpTvZHQvOWnhqnVpFO5ZW4tLzq7wMAADgZJQnNQn6JSxsP5EmiJKH5cthtuqpPsiRpDqvcAQBwWud0T9K11157xsfz8vLOJwvQZFbsPiqPJaXGRyg5Jsx0HMCYcX1T9PY3e7Vgc5ZOlLtZCh8AgFM4p5IUExNz1sdvueWW8woENIUlO6qn2rH0N5q3Ae1aqHWLMB3KO6Evv8/RlVVXlgAAwA/OqSS99dZbTZUDaFLLdnA/EiBJNptN4/qm6LXFuzR3YyYlCQCAU+CeJAS8fceKtT+3RMEOm4Z0YtljYHzVKndfbstRQanLcBoAAHwPJQkBb2nVVaT+7VoqwtngrcGAgNE9OUppCZEqr/BoweZs03EAAPA5lCQEvJqpdmlMtQOkyil31VeTWOUOAICTUZIQ0CrcHi3fVVWSurBoA1CtemPZ5TuP6lhRmeE0AAD4FkoSAtp3h/JVWFqhmLBg9W595tUZgeakY6sI9W4dI7fH0mcZWabjAADgUyhJCGjVU+2GpsXJYbcZTgP4luopd3M3MOUOAIDaKEkIaEt3HJEkDUtjqh3wY1f1TZbNJq3em6vMvBOm4wAA4DMoSQhYhaUurd+fJ4n9kYBTSY4J04UdYiVJn3zH1SQAAKpRkhCwVu7OVYXHUoe4cLWNDTcdB/BJ41jlDgCAk1CSELCWVU+14yoScFpX9EqSw25TxqEC7T5SZDoOAAA+gZKEgLV0Z9XS3525Hwk4nbhIp4ZV7SE2d+Nhw2kAAPANlCQEpEN5J7T7SLEcdpvSU+NMxwF82g8byx6SZVmG0wAAYB4lCQGpeqpd3zYxig4NNpwG8G2jeiYqJMiuXUeKteVwgek4AAAYR0lCQFqyg6l2QH1FhQbrsq4JkphyBwCARElCAPJ4LH1Tcz8SizYA9TG+X9XGshszmXIHAGj2KEkIOJszC3S8xKUoZ5D6tm1hOg7gFy7rlqBIZ5AO5Z3Quv3HTccBAMAoShICzpKq+5GGpMYp2MEQB+ojNNihUT0SJUlzNrBnEgCgeeMnSAScZTuYagc0RPXGsp9uOqwKt8dwGgAAzKEkIaCUlFdozb5cSSzaAJyrYZ1bqWV4sI4WlWvl7lzTcQAAMIaShICyak+uXG5LrVuEqUNcuOk4gF8Jdtg1tneypMo9kwAAaK4oSQgo1VPtLu7SSjabzXAawP9Ubyw7LyNLZRVuw2kAADCDkoSAsrRq0YZhaUy1Axriwg6xSox2qrC0Qou3HTEdBwAAIyhJCBjZBaXanl0km026KDXOdBzALznsNl3Vp2rPpO/YWBYA0DxRkhAwllZNtevTOkYtI0IMpwH8V/WUuy+2ZKukvMJwGgAAvI+ShICxrHqqHUt/A+elT5sYtY8L1wmXWwu3ZJuOAwCA11GSEBA8HkvLdh6TxNLfwPmy2Ww1V5PmbmRjWQBA80NJQkD4PqtQR4vKFB7i0IB2LU3HAfxe9cayi7cfUV5JueE0AAB4l9GS9PTTT+vCCy9UVFSUEhISNGHCBG3btq3OOaWlpZo0aZLi4uIUGRmpiRMnKjub6R+oa9nOyql2gzvGKiSI7g+cry6JUeqWFCWX29Lnm7NMxwEAwKuM/jS5ePFiTZo0SStXrtTChQvlcrk0atQoFRcX15xz3333ae7cufrwww+1ePFiZWZm6tprrzWYGr6oetEGptoBjaf6atIcptwBAJqZIJPffP78+XU+f/vtt5WQkKC1a9fq4osvVn5+vt58803NnDlTl112mSTprbfeUvfu3bVy5UoNGTLERGz4mFKXW6v35EqShrNoA9BoxvdN0XOfb9OKXceUU1iqhKhQ05EAAPAKoyXpx/Lz8yVJsbGxkqS1a9fK5XJpxIgRNed069ZN7dq104oVK05ZksrKylRWVlbzeUFBgSTJ5XLJ5XI1ZXw0ker37XTv38pdx1RW4VFitFPtWzp5n3HezjbmmoukqGD1axujDQfyNWf9Qd2a3t50pIDFmIM3Md7gbb405uqbwWdKksfj0b333quhQ4eqV69ekqSsrCyFhISoRYsWdc5NTExUVtap58g//fTTmjZt2knHFyxYoPDw8EbPDe9ZuHDhKY9/vM8uya72zhOaN2+ed0MhoJ1uzDUnHR02bZBD7yz5XvHHN5uOE/AYc/Amxhu8zRfGXElJSb3O85mSNGnSJGVkZGjZsmXn9XUeeOABTZkypebzgoICtW3bVqNGjVJ0dPT5xoQBLpdLCxcu1MiRIxUcHHzS469NXyGpUNdf0ldX9E32fkAEnLONuebkgsIyffzcYu0tsql3+qVq25JfNjUFxhy8ifEGb/OlMVc9y+xsfKIkTZ48WZ988omWLFmiNm3a1BxPSkpSeXm58vLy6lxNys7OVlJS0im/ltPplNPpPOl4cHCw8TcF5+dU7+GRwjJtzSqUJF3SLZH3GI2Kfzek1rHBGtIpTt/sOqb5W47o7kvTTEcKaIw5eBPjDd7mC2Ouvt/f6Op2lmVp8uTJmjVrlr788kt17NixzuMDBw5UcHCwFi1aVHNs27Zt2r9/v9LT070dFz7om12Vq9r1SI5Wq8iTyzGA81e9seycDaxyBwBoHoyWpEmTJumdd97RzJkzFRUVpaysLGVlZenEiROSpJiYGN1xxx2aMmWKvvrqK61du1a333670tPTWdkOkmot/d2FVe2ApjKmV5KCHTZ9n1WoHdmFpuMAANDkjJakGTNmKD8/X5deeqmSk5NrPt5///2ac1544QVdddVVmjhxoi6++GIlJSXpP//5j8HU8BWWZWnpjspNZIensT8S0FRahIfo4qo9yOayZxIAoBkwek+SZVlnPSc0NFTTp0/X9OnTvZAI/mRnTpGyC8rkDLLrgg4tTccBAtr4fila9H2O5mzM1H0ju8hms5mOBABAkzF6JQk4H0uqptoN6hir0GCH4TRAYBvRPVGhwXbtPVaiTYfyTccBAKBJUZLgt5ZVT7XrzP1IQFOLcAZpRPdESSzgAAAIfJQk+KWyCrdW7s6VJA3vzP1IgDeMq1rl7pPvDsvjOft0aQAA/BUlCX5p3b48nXC51SrSqW5JUabjAM3CpV3jFRUapKyCUn27N9d0HAAAmgwlCX5p2c7KqXbD0uK4gRzwEmeQQ2N6Vm7kPYdV7gAAAYySBL9Usz8SU+0Arxrfr3LK3WebDsvl9hhOAwBA06Akwe8cLy6vWV1rGIs2AF6V3ilOrSJDdLzEpWU7j5qOAwBAk6Akwe98s+uYLEvqmhilxOhQ03GAZiXIYdcVvZMlsbEsACBwUZLgd5ZWLf3NVSTAjPFVq9wt2JytUpfbcBoAABofJQl+xbKsmvuRKEmAGQPatVTrFmEqKqvQV9/nmI4DAECjoyTBr+w5WqxDeScU4rBrcMdY03GAZslut+mqvpVT7ljlDgAQiChJ8CvVN4oPbN9S4SFBhtMAzde4PpVT7hZ9n6PCUpfhNAAANC5KEvxKzdLfXZhqB5jUMyVaneIjVF7h0cIt2abjAADQqChJ8Bsut0crdh2TJA1PY38kwCSbzVazgANT7gAAgYaSBL/x3cF8FZVVqGV4sHqmRJuOAzR71SVp2Y6jyi0uN5wGAIDGQ0mC31i2s/Iq0tC0VrLbbYbTAOgUH6leraNV4bH02abDpuMAANBoKEnwG8urp9qx9DfgM6oXcGBjWQBAIKEkwS+UVEjfHSqQJA3rzP1IgK+4qmrK3eq9ucrKLzWcBgCAxkFJgk9zeyyt2pOr+QfscnssdWwVrtYtwkzHAlCldYswXdihpSxL+uQ7riYBAAIDG83AZ83POKxpc7focH6pqvt8dkGZ5mcc1pheyWbDAagxvm+Kvt17XDNX7Vd8lFMJUaEa1DFWDu4dBAD4Ka4kwSfNzzisu95ZV1WQflBS7tZd76zT/AxuEgd8hTPYIUnafbRYv31vg258Y6WGPfMlf08BAH6LkgSf4/ZYmjZ3i6wznDNt7ha5PWc6A4A3zM84rP/56LuTjmfll/ILDQCA36Ikwees3pN70hWk2ixJh/NLtXpPrvdCATjJmX6hUX2MX2gAAPwRJQk+J6ewfitk1fc8AE2DX2gAAAIVJQk+JyEqtFHPA9A0+IUGACBQUZLgcwZ1jFVyzOkLkE1Sckzl6lkAzOEXGgCAQEVJgs9x2G267aIOp3ysekHhR8f1YHlhwLDqX2ic6W8iv9AAAPgjShJ8Tv4Jl95dtV+S5AyqO0STYkI14+YB7JME+ACH3aZHx/WQpNMWJX6hAQDwR2wmC59iWZb+8NFG7c8tUdvYMH189zBtyTyuBUtXadTwwUpPS+AHLsCHjOmVrBk3D6i18XNd0WHBBlIBAHB+KEnwKW8t36vPN2crxGHX9J8PUGxkiAZ3jNWxrZYGd4ylIAE+aEyvZI3skaTVe3KVU1iqhKhQzf3ukGauOqA/zs7QvN8OlzPIYTomAAD1RkmCz1i//7ie+myrJOmhK7urT5sWZgMBqDeH3ab01Liaz3ukRGvB5hztPlKs1xfv1j2XdzaYDgCAc8M9SfAJeSXlmjxzvSo8lq7snaxb0tubjgTgPMSEBevhq7pLkl7+aqf2Hi02nAgAgPqjJME4j8fS7z7YqEN5J9QhLlx/mthbNhvT6gB/N75vioaltVJ5hUcPf5why7JMRwIAoF4oSTDujaW7tej7HIUE2TX9pgGKCuVGbyAQ2Gw2PT6hl0KC7Fq646g++e6w6UgAANQLJQlGrdmbq2c/3yZJmjqup3qmxBhOBKAxdWwVoUmXpkmSHvtkiwpKXYYTAQBwdpQkGHOsqEyTZ66X22Pp6n4punFQW9ORADSBX1/aSZ1aRehIYZn+XPVLEQAAfBklCUZ4PJbu+2CjsgpKlRofoaeu4T4kIFA5gxx6fEIvSdI/V+7TxgN5ZgMBAHAWlCQYMWPxLi3ZfkShwXa9etNARThZjR4IZEPTWmlCvxRZlvTgrE2qcHtMRwIA4LQoSfC6FbuO6c8LKqfcPHZ1L3VNijKcCIA3PHRlD0WHBmlzZoH+tXKf6TgAAJwWJQledaSwTL95b708lvTTgW103QXchwQ0F/FRTv3P2G6SpD8v2K6s/FLDiQAAODVKErzG7bF07/vrdaSwTF0SI/X41b1MRwLgZTde2E7927VQUVmFHvtks+k4AACcEiUJXvPSoh1avvOYwkMcevWmAQoLcZiOBMDL7HabnpzQWw67TZ9tytJX3+eYjgQAwEkoSfCKZTuO6qUvd0iSnryml9ISuA8JaK56pETrl0M7SJIemZOhE+Vus4EAAPgRShKaXHZBqe59f70sS7pxUFtd07+N6UgADLt3RBclx4TqQO4JvVz1CxQAAHwFJQlNqsLt0T3/Xq+jReXqnhytR8f1NB0JgA+IcAZp6vjKfw9eX7Jb27MLDScCAOAHlCQ0qRe+2K7Ve3IV6QzSqzcNUGgw9yEBqDSqR6JGdE9QhcfSH2dlyLIs05EAAJBESUIT+mpbjqZ/tUuS9KeJvdWxVYThRAB8ic1m09TxPRUW7NDqvbn6aO1B05EAAJBESUITycw7oSnvb5Ak3ZLeXlf1STEbCIBPatMyXPeO6CxJeuqzrcotLjecCAAAShKagKvqPqTjJS71bh2jh67sbjoSAB/2y2Ed1TUxSsdLXPrTvK2m4wAAQElC43vu821au++4okKDNP3nA+QM4j4kAKcX7LDrqWsrN5f+YM1Brd6TazgRAKC5oyShUX2xJVuvL9ktSXrup33VLi7ccCIA/mBg+1jdOKitJOmPszepvMJjOBEAoDmjJKHRHMgt0e8+3ChJ+uXQjhrTK8lwIgD+5H/GdFNsRIi2Zxfpb8t2m44DAGjGKEloFOUVHk3+93rln3CpX9sWun9sN9ORAPiZFuEheuiKynsYX1q0QwdySwwnAgA0V5QkNIqn523VxgN5igkL1is/76+QIIYWgHN37YDWGtIpVqUujx75mL2TAABm8JMsztu8TYf11vK9kqTnr+urNi25DwlAw9hsNj0xobeCHTZ9te2I5mdkmY4EAGiGKEk4L/uOFesPH30nSfqvSzrp8u6JhhMB8HdpCZH69SWpkqSpczerqKzCcCIAQHNDSUKDlbrcmjRznQrLKnRB+5b6/aiupiMBCBCTfpKm9nHhyi4o0/MLtpuOAwBoZihJaLAnPt2ijEMFio0I0cs/769gB8MJQOMIDXbosasr9056+5s9yjiUbzgRAKA54adaNMjcjZl6Z+V+2WyV9yElx4SZjgQgwFzSJV5X9UmWx5IemrVJbg+LOAAAvIOShHO2+0iR7v+/yvuQJl2apku7JhhOBCBQPXxVD0U5g7TxYL5mrtpnOg4AoJmgJOGclLrcuvvddSoud2twx1jdO6Kz6UgAAlhidKh+P7ryfsdn529TTmGp4UQAgOaAkoRzMnXOZn2fVahWkSF6+cb+CuI+JABN7OYh7dWnTYwKyyr0xCdbTccBADQD/ISLevvPuoN679sDstmkv9zQXwnRoaYjAWgGHHabnpzQW3abNGdjppZsP2I6EgAgwFGSUC87sgv10KwMSdK9l3fR0LRWhhMBaE56t4nRLekdJEkPf5yhUpfbbCAAQECjJOGsSsordPe763TC5dawtFaafFma6UgAmqHfjeqixGin9h0r0atf7zIdBwAQwChJOCPLsvTH2RnakVOkhCinXryhnxx2m+lYAJqhqNBgPTqupyTpta93adeRIsOJAACBipKEM/pwzUH9Z90h2W3Syzf2V6tIp+lIAJqxsb2SdGnXeJW7PXp4doYsi72TAACNj5KE09p6uEAPf1x5H9LvRnXV4E5xhhMBaO5sNpseG99LziC7vtl1TLM3HDIdCQAQgChJOKWisgpNenedyio8urRrvO66JNV0JACQJLWLC9dvLq/co+2JT7Yqv8RlOBEAINBQknASy7L0wH82affRYiXHhOr56/rJzn1IAHzIr4Z3UlpCpI4Vl+uZz783HQcAEGCMlqQlS5Zo3LhxSklJkc1m0+zZs+s8blmWHnnkESUnJyssLEwjRozQjh07zIRtRt5dtV9zN2YqyG7TKz/vr9iIENORAKCOkCC7npzQS5I0c9V+rd133HAiAEAgMVqSiouL1bdvX02fPv2Ujz/77LN66aWX9Nprr2nVqlWKiIjQ6NGjVVpa6uWkzUfGoXw99skWSdL/jOmmge1jDScCgFMb3ClOPx3YRpL00KxNcrk9hhMBAAKF0ZI0duxYPfHEE7rmmmtOesyyLL344ov64x//qKuvvlp9+vTRP//5T2VmZp50xQmNo6DUpUkz16m8wqMR3RP1/4Z3NB0JAM7owSu6q0V4sL7PKtTby/eajgMACBBBpgOczp49e5SVlaURI0bUHIuJidHgwYO1YsUK3XDDDad8XllZmcrKymo+LygokCS5XC65XNzcezqWZem/P9iofcdK1LpFqP50TQ9VVFSYjiVJNe8b7x+8hTHnP6JCbPrDqC56cPZmPb9wm0Z1b6WUFmGmY50zxhy8ifEGb/OlMVffDD5bkrKysiRJiYmJdY4nJibWPHYqTz/9tKZNm3bS8QULFig8PLxxQwaQJYdt+nyvQw6bpevbFGn5VwtNRzrJwoW+lwmBjTHnH8IsqVOUQ7sLPZr898X6f938d9odYw7exHiDt/nCmCspKanXeT5bkhrqgQce0JQpU2o+LygoUNu2bTVq1ChFR0cbTOa7Nh7M15zVqyVZemBsN92a3t50pDpcLpcWLlyokSNHKjg42HQcNAOMOf/T5YJCXf3qSm06bldIxwEa0T3BdKRzwpiDNzHe4G2+NOaqZ5mdjc+WpKSkJElSdna2kpOTa45nZ2erX79+p32e0+mU0+k86XhwcLDxN8UX5Ze49Nv3v5PLbWlsryTdMTxVNptvLvfNewhvY8z5j55tYvX/hnfSa4t36fFPv9fFXRMV4fTZ/8WdFmMO3sR4g7f5wpir7/f32X2SOnbsqKSkJC1atKjmWEFBgVatWqX09HSDyQKHZVn63YcbdSjvhNrFhuuZn/bx2YIEAGfz28s7q03LMGXml+ovi9guAgDQcEZLUlFRkTZs2KANGzZIqlysYcOGDdq/f79sNpvuvfdePfHEE5ozZ442bdqkW265RSkpKZowYYLJ2AHjb0v36Iut2Qpx2PXqTQMUHcpvkwD4r7AQhx67uqck6c1le7T1cP2mVAAA8GNGS9KaNWvUv39/9e/fX5I0ZcoU9e/fX4888ogk6Q9/+IPuuece3XnnnbrwwgtVVFSk+fPnKzQ01GTsgLB233E9M79yl/qHx/VQr9YxhhMBwPm7rFuixvRMkttj6aFZm+TxWKYjAQD8kNEJ25deeqks6/T/A7PZbHrsscf02GOPeTFV4MstLtfkmetU4bE0rm+Kbh7cznQkAGg0j47voaU7jmjd/jy9v+aAbhzEv3EAgHPjs/ckoWl4PJamfLBBh/NL1alVhJ6+tjf3IQEIKMkxYZoyqqsk6U/zvtfRorKzPAMAgLooSc3Ma0t26ettR+QMsmv6TQMU6YerPwHA2dya3l49kqOVf8Klpz7dajoOAMDPUJKakVW7j+l/P98mSXrs6p7qnsy+UQACU5DDriev6SWbTfrP+kP6ZtdR05EAAH6EktRMHC0q0z3/Xi+PJV3bv7Wuu6Ct6UgA0KT6t2upm6ruufzj7AyVVbgNJwIA+AtKUjPg9li6970NyiksU+eESD1xTS/uQwLQLPz36G5qFenU7iPF+uvi3abjAAD8BCWpGXjly51atvOowoIdevWmAQoP4T4kAM1DTFiwHr6quyTpla92au/RYsOJAAD+gJIU4L7ZeVQvLtouSXpiQi91TowynAgAvGt83xQNS2ul8gqPHv4444xbTwAAIFGSAlpOQal+894GWZZ0/QVtNXFgG9ORAMDrbDabHp/QSyFBdi3dcVRzvztsOhIAwMdRkgJUhduj37y3XkeLytQtKUrTru5pOhIAGNOxVYQmXZomSXr8ky3KP+EynAgA4MsoSQHqL4t2aOXuXEWEODT9pgEKDXaYjgQARv360k7q1CpCRwrL9OcF20zHAQD4MEpSAFq8/Yhe+WqnJOnpiX2UGh9pOBEAmOcMcuiJCb0kSf9auU8bD+SZDQQA8FmUpABzOP+E7nu/8j6kmwa30/i+KaYjAYDPuCitla7p31qWJT04a5Mq3B7TkQAAPoiSFEBcbo9+8+/1yi0uV8+UaD18VQ/TkQDA5zx4RXdFhwZpc2aB/rlin+k4AAAfREkKIP+7YJu+3XtcUc4gvcp9SABwSvFRTv3P2G6SpD8v2Kas/FLDiQAAvoaSFCAWbc2u2U3+2Z/2Ufu4CMOJAMB33XhhO/Vv10LF5W499slm03EAAD6GkhQADh4v0ZQPNkqSbruog8b2TjacCAB8m91u05MTestht+mzTVn66vsc05EAAD6EkuTnyis8mjxzvfJPuNS3TYwevKK76UgA4Bd6pETrl0M7SJIe/jhDJ8rdZgMBAHwGJcnPPTP/e204kKfo0CC98vMBCgniLQWA+rp3RBclx4Tq4PETevnLHabjAAB8BD9R+7H5GVl6c9keSdKfr+untrHhhhMBgH+JcAZp6viekqTXl+zW9uxCw4kAAL6AkuSn9h8r0X9/VHkf0q+Gd9TIHomGEwGAfxrdM0kjuieqwmPpj7My5PFYpiMBAAyjJPmhsgq3Js1cp8LSCg1o10J/GNPNdCQA8GtTx/dQWLBDq/fm6qN1B03HAQAYRknyQ09+ulWbDuWrZXiwXvn5AAU7eBsB4Hy0aRmue0d0liQ9/dlW5RaXG04EADCJn679zCffZdbsEP/89f2U0iLMcCIACAy/HNZR3ZKidLzEpac/22o6DgDAIEqSH9lztFj3/98mSdLdl6bqJ10TDCcCgMAR7LDryWt6SZI+XHtQq3YfM5wIAGAKJclPlLrcuvvddSoqq9CgjrGaMrKL6UgAEHAGto/VjYPaSpL+ODtD5RUew4kAACZQkvzEtLlbtPVwgeIiQvTyjf0VxH1IANAk/mdMN8VGhGhHTpH+tmy36TgAAAP4SdsPzF5/SP9evV82m/TiDf2UGB1qOhIABKwW4SF66IrukqSXFu3QgdwSw4kAAN5GSfJxO3OK9OCsyvuQ7rmss4Z3jjecCAAC37UDWmtIp1iVujx6+OMMWRZ7JwFAc0JJ8mEnyt26+921Kil366LUOP328s6mIwFAs2Cz2fTEhN4Kdtj09bYjmp+RZToSAMCLKEk+7OGPM7Q9u0jxUU795Yb+cthtpiMBQLORlhCpX1+SKkmaOnezisoqDCcCAHgLJclHfbjmgD5ae1B2m/TSDf0VH+U0HQkAmp1JP0lT+7hwZReU6c8LtpmOAwDwEkqSD9qWVaiHP86QJE0Z2UXpqXGGEwFA8xQa7NBjV1funfSPb/Yq41C+4UQAAG+gJPmY4rIK3f3uWpW6PLq4S7zuvjTNdCQAaNYu6RKvq/oky2NJD83aJLeHRRwAINBRknyIZVl6cNYm7TpSrKToUL1wXV/ZuQ8JAIx7+KoeinIGaePBfM1ctc90HABAE6Mk+ZB/rz6gjzdkymG36eWf91dcJPchAYAvSIwO1e9Hd5UkPTt/m3IKSg0nAgA0JUqSj9icma+pczdLkv57dFdd2CHWcCIAQG03D2mvPm1iVFhWocc/3Wo6DgCgCVGSfEBhqUuT3l2n8gqPLu+WoDuHdzIdCQDwIw67TU9O6C27TZq7MVNLth8xHQkA0EQoSYZZlqX7/2+T9h4rUesWYfoz9yEBgM/q3SZGt6R3kFS5l12py202EACgSVCSDPvXyn36dNNhBVXdh9QiPMR0JADAGfxuVBclRju171iJXv1qp+k4AIAmQEky6LuDeXrik8p57Q9c0V0D2rU0nAgAcDZRocF6dFxPSdKMxbu0M6fIcCIAQGOjJBmSf8KlSTPXqdzt0eieifrl0A6mIwEA6mlsryRd2jVeLrelh2dnyLLYOwkAAgklyUvcHksrdh3TxxsOacWuo/r9Bxt0IPeE2saG6dmf9pXNxn1IAOAvbDabHhvfS84gu1bsPqZZ6w+ZjgQAaERBpgM0B/MzDmva3C06nF93X40gu03Tfz5AMWHBhpIBABqqXVy4fnN5Zz33+TY9+elWXdYtgftKASBAcCWpic3POKy73ll3UkGSpAqPpcy8EwZSAQAaw6+Gd1JaQqSOFZfrmfnbTMcBADQSSlITcnssTZu7RaebqW6TNG3uFrk9zGUHAH8UEmTXkxN6SZL+vXq/1u7LNZwIANAYKElNaPWe3FNeQapmSTqcX6rVe/ifKgD4q8Gd4vTTgW0kSQ/NypDL7TGcCABwvihJTSin8PQFqSHnAQB804NXdFeL8GB9n1Wot5bvMR0HAHCeKElNKCEqtFHPAwD4ptiIED04trsk6YWFO3SI+00BwK9RkprQoI6xSo4J1ekW97ZJSo4J1aCOsd6MBQBoAj8d2EYXdmipEy63ps7ZbDoOAOA8UJKakMNu06PjekjSSUWp+vNHx/WQw84eSQDg7+x2m568preC7DYt3JKtBZuzTEcCADQQJamJjemVrBk3D1BSTN0pdUkxoZpx8wCN6ZVsKBkAoLF1SYzSry7uJEmaOmezissqDCcCADQEm8l6wZheyRrZI0mr9+Qqp7BUCVGVU+y4ggQAgec3l3XW3I2ZOnj8hP6yaIcevKK76UgAgHPElSQvcdhtSk+N09X9Wis9NY6CBAABKizEoceu7ilJenPZHm3JLDCcCABwrihJAAA0ssu6JWpMzyS5PZYemr1JHjYNBwC/QkkCAKAJPDq+hyJCHFq/P0/vfXvAdBwAwDmgJAEA0ASSY8I0ZVRXSdKf5m3V0aIyw4kAAPVFSQIAoIncmt5ePZKjVVBaoSc/3Wo6DgCgnihJAAA0kSCHXU9d21s2mzRr/SF9s/Oo6UgAgHqgJAEA0IT6tW2hmwe3lyT9cXaGyirchhMBAM6GkgQAQBP7/eiuahXp1O6jxfrr4t2m4wAAzoKSBABAE4sJC9bDV1VuKvvKVzu152ix4UQAgDOhJAEA4AXj+6ZoWForlVd49MjHGbIs9k4CAF9FSQIAwAtsNpsen9BLIUF2Ld1xVHO/O2w6EgDgNChJAAB4ScdWEZp0aZok6fFPtij/hMtwIgDAqVCSAADwol9f2kmdWkXoSGGZ/vfzbabjAABOgZIEAIAXOYMcemJCL0nSO6v2ae2+41q1J1drj9q0ak+u3B7uVQIA04JMBwAAoLm5KK2VrunfWrPWH9L1f12hCo8lyaF/7lij5JhQPTquh8b0SjYdEwCaLa4kAQBgwJBOcZJUVZB+kJVfqrveWaf5GSzsAACmUJIAAPAyt8fSi19sP+VjVtXHIx9vVk5Bqcoq3F7NBgBguh0AAF63ek+uDueXnvGcnMIyDXpqkSQp2GFThDNIkVUfEVUfUc4gRTgdtf476KTzIp1BigytPC/SGaSwYIdsNps3/phNyu2xtHpPrnIKS5UQFapBHWPlsPv/n6upuT1WzT1wcXtylZ6WwOtWD4y3hvPXMecXJWn69Ol67rnnlJWVpb59++rll1/WoEGDTMcCAKBBcgrPXJB+zOW2lFfiUl7J+S8ZbreppjzVLVQORTqDFVlVuiKcQYoKDVJESK3/dgYpsuq8CKdDESFBshv4YWd+xmFNm7ulTtHkXq6zq/u6cQ9cfTHeGs6fx5zPl6T3339fU6ZM0WuvvabBgwfrxRdf1OjRo7Vt2zYlJCSYjgcAwDlLiAqt13nv3DFIvdu0UHFZhYqqPorLKlRU+sN/F5e7VVha9d9lFSos++G/f3iOW8XlFbIsyWNJhaUVKiytaJQ/S3iI46QrV9VlKqLqKlZkVdGKDK37eHXZqj4W7Dj7XQDzMw7rrnfW6cdrAFbfyzXj5gE+/8OXCbxuDcPr1nD+/tr5fEl6/vnn9atf/Uq33367JOm1117Tp59+qr///e+6//77DacDAODcDeoYq+SYUGXll570A4Qk2SQlxYQqPbWVHHabYsKCz/t7ejyWSlzuH8pT6Q9Fqri8uni5Ty5ktf67uMytwlKXisvdNUuVl5S7VVLuVk5h2XlndAbZT32FK7TyCldYsEMfrDl4ytes+tgD/9kkj8cycoXLV3k8lh6cncHrdo543RrubK+dTdK0uVs0skeSz0698+mSVF5errVr1+qBBx6oOWa32zVixAitWLHilM8pKytTWdkP/1AXFBRIklwul1wudjb3R9XvG+8fvIUxB294aGxX3fPeRtmkOj9I2Go97nFXyNOI6zY47ZIzzKHYMIckZ4O/jmVZKqvwVJUo9w9Fq6pkFVcfq7rSVfyjK1pFpRUqqjpeXO5WeYVHklRW4VFZRbmOFZc3ONvxEpfunrm+wc9vrnjdGobXrWEsSYfzS7ViZ44Gd4z16veu7//bfbokHT16VG63W4mJiXWOJyYm6vvvvz/lc55++mlNmzbtpOMLFixQeHh4k+SEdyxcuNB0BDQzjDk0tdu72PSfvXbllf/wm9SYEEvXdvDIvW+tPttnMFwDOSRFV33UCKn6iDr1cyo8UplbKq36KHNLZW7bD59XPb630KYteWefkhcfainy/C++BYwil3Sk9Oy/red1q4vXreHq+9otWLpKx7Z6dwPtkpKSep3n0yWpIR544AFNmTKl5vOCggK1bdtWo0aNUnR09BmeCV/lcrm0cOFCjRw5UsHB/CuEpseYg7dcIekPHksrdx3RlyvW6rL0gRqSGu+z009MW7UnVzf/fc1Zz3vh5xd6/bfTvozXrWF43Rquvq/dqOGDvf7aVc8yOxufLkmtWrWSw+FQdnZ2nePZ2dlKSko65XOcTqeczpOnEAQHB/PDjp/jPYS3MebgDcGShnZOUP4OS0M7JzDmziA9LaF+93L5yRLD3sLr1jC8bg3ny69dff+N9enNZENCQjRw4EAtWrSo5pjH49GiRYuUnp5uMBkAAPA2h92mR8f1kPTDvVvVqj9/dFwPfmD9EV63huF1a7hAeO18uiRJ0pQpU/TGG2/oH//4h7Zu3aq77rpLxcXFNavdAQCA5mNMr2TNuHmAkmLqLqOeFBPq80sKm8Tr1jC8bg3n76+dT0+3k6Trr79eR44c0SOPPKKsrCz169dP8+fPP2kxBwAA0DyM6ZWskT2StHpPrnIKS5UQFapBHWN9+rfSvqD6dVuxM0cLlq7SqOGDmSpWD4y3hvPnMefzJUmSJk+erMmTJ5uOAQAAfITDblN6apzpGH7HYbdpcMdYHdtqaTA/6Ncb463h/HXM+fx0OwAAAADwJkoSAAAAANRCSQIAAACAWihJAAAAAFALJQkAAAAAaqEkAQAAAEAtlCQAAAAAqIWSBAAAAAC1UJIAAAAAoBZKEgAAAADUQkkCAAAAgFooSQAAAABQCyUJAAAAAGoJMh2gqVmWJUkqKCgwnAQN5XK5VFJSooKCAgUHB5uOg2aAMQdvY8zBmxhv8DZfGnPVnaC6I5xOwJekwsJCSVLbtm0NJwEAAADgCwoLCxUTE3Pax23W2WqUn/N4PMrMzFRUVJRsNpvpOGiAgoICtW3bVgcOHFB0dLTpOGgGGHPwNsYcvInxBm/zpTFnWZYKCwuVkpIiu/30dx4F/JUku92uNm3amI6BRhAdHW38LxaaF8YcvI0xB29ivMHbfGXMnekKUjUWbgAAAACAWihJAAAAAFALJQk+z+l06tFHH5XT6TQdBc0EYw7expiDNzHe4G3+OOYCfuEGAAAAADgXXEkCAAAAgFooSQAAAABQCyUJAAAAAGqhJAEAAABALZQk+Kynn35aF154oaKiopSQkKAJEyZo27ZtpmOhmfjTn/4km82me++913QUBLBDhw7p5ptvVlxcnMLCwtS7d2+tWbPGdCwEKLfbrYcfflgdO3ZUWFiYUlNT9fjjj4s1vNAYlixZonHjxiklJUU2m02zZ8+u87hlWXrkkUeUnJyssLAwjRgxQjt27DATth4oSfBZixcv1qRJk7Ry5UotXLhQLpdLo0aNUnFxseloCHDffvut/vrXv6pPnz6moyCAHT9+XEOHDlVwcLDmzZunLVu26M9//rNatmxpOhoC1DPPPKMZM2bolVde0datW/XMM8/o2Wef1csvv2w6GgJAcXGx+vbtq+nTp5/y8WeffVYvvfSSXnvtNa1atUoREREaPXq0SktLvZy0flgCHH7jyJEjSkhI0OLFi3XxxRebjoMAVVRUpAEDBujVV1/VE088oX79+unFF180HQsB6P7779fy5cu1dOlS01HQTFx11VVKTEzUm2++WXNs4sSJCgsL0zvvvGMwGQKNzWbTrFmzNGHCBEmVV5FSUlL0u9/9Tr///e8lSfn5+UpMTNTbb7+tG264wWDaU+NKEvxGfn6+JCk2NtZwEgSySZMm6corr9SIESNMR0GAmzNnji644AL97Gc/U0JCgvr376833njDdCwEsIsuukiLFi3S9u3bJUkbN27UsmXLNHbsWMPJEOj27NmjrKysOv9vjYmJ0eDBg7VixQqDyU4vyHQAoD48Ho/uvfdeDR06VL169TIdBwHqvffe07p16/Ttt9+ajoJmYPfu3ZoxY4amTJmiBx98UN9++61+85vfKCQkRLfeeqvpeAhA999/vwoKCtStWzc5HA653W49+eSTuummm0xHQ4DLysqSJCUmJtY5npiYWPOYr6EkwS9MmjRJGRkZWrZsmekoCFAHDhzQb3/7Wy1cuFChoaGm46AZ8Hg8uuCCC/TUU09Jkvr376+MjAy99tprlCQ0iQ8++EDvvvuuZs6cqZ49e2rDhg269957lZKSwpgDfoTpdvB5kydP1ieffKKvvvpKbdq0MR0HAWrt2rXKycnRgAEDFBQUpKCgIC1evFgvvfSSgoKC5Ha7TUdEgElOTlaPHj3qHOvevbv2799vKBEC3X//93/r/vvv1w033KDevXvrF7/4he677z49/fTTpqMhwCUlJUmSsrOz6xzPzs6ueczXUJLgsyzL0uTJkzVr1ix9+eWX6tixo+lICGCXX365Nm3apA0bNtR8XHDBBbrpppu0YcMGORwO0xERYIYOHXrStgbbt29X+/btDSVCoCspKZHdXvdHP4fDIY/HYygRmouOHTsqKSlJixYtqjlWUFCgVatWKT093WCy02O6HXzWpEmTNHPmTH388ceKioqqmbMaExOjsLAww+kQaKKiok663y0iIkJxcXHcB4cmcd999+miiy7SU089peuuu06rV6/W66+/rtdff910NASocePG6cknn1S7du3Us2dPrV+/Xs8//7x++ctfmo6GAFBUVKSdO3fWfL5nzx5t2LBBsbGxateune6991498cQT6ty5szp27KiHH35YKSkpNSvg+RqWAIfPstlspzz+1ltv6bbbbvNuGDRLl156KUuAo0l98skneuCBB7Rjxw517NhRU6ZM0a9+9SvTsRCgCgsL9fDDD2vWrFnKyclRSkqKbrzxRj3yyCMKCQkxHQ9+7uuvv9ZPfvKTk47feuutevvtt2VZlh599FG9/vrrysvL07Bhw/Tqq6+qS5cuBtKeHSUJAAAAAGrhniQAAAAAqIWSBAAAAAC1UJIAAAAAoBZKEgAAAADUQkkCAAAAgFooSQAAAABQCyUJAAAAAGqhJAEAAABALZQkAADOwGazafbs2aZjAAC8iJIEAPBZt912m2w220kfY8aMMR0NABDAgkwHAADgTMaMGaO33nqrzjGn02koDQCgOeBKEgDApzmdTiUlJdX5aNmypaTKqXAzZszQ2LFjFRYWpk6dOumjjz6q8/xNmzbpsssuU1hYmOLi4nTnnXeqqKiozjl///vf1bNnTzmdTiUnJ2vy5Ml1Hj969KiuueYahYeHq3PnzpozZ07T/qEBAEZRkgAAfu3hhx/WxIkTtXHjRt1000264YYbtHXrVklScXGxRo8erZYtW+rbb7/Vhx9+qC+++KJOCZoxY4YmTZqkO++8U5s2bdKcOXOUlpZW53tMmzZN1113nb777jtdccUVuummm5Sbm+vVPycAwHtslmVZpkMAAHAqt912m9555x2FhobWOf7ggw/qwQcflM1m069//WvNmDGj5rEhQ4ZowIABevXVV/XGG2/of/7nf3TgwAFFRERIkj777DONGzdOmZmZSkxMVOvWrXX77bfriSeeOGUGm82mP/7xj3r88cclVRavyMhIzZs3j3ujACBAcU8SAMCn/eQnP6lTgiQpNja25r/T09PrPJaenq4NGzZIkrZu3aq+ffvWFCRJGjp0qDwej7Zt2yabzabMzExdfvnlZ8zQp0+fmv+OiIhQdHS0cnJyGvpHAgD4OEoSAMCnRUREnDT9rbGEhYXV67zg4OA6n9tsNnk8nqaIBADwAdyTBADwaytXrjzp8+7du0uSunfvro0bN6q4uLjm8eXLl8tut6tr166KiopShw4dtGjRIq9mBgD4Nq4kAQB8WllZmbKysuocCwoKUqtWrSRJH374oS644AINGzZM7777rlavXq0333xTknTTTTfp0Ucf1a233qqpU6fqyJEjuueee/SLX/xCiYmJkqSpU6fq17/+tRISEjR27FgVFhZq+fLluueee7z7BwUA+AxKEgDAp82fP1/Jycl1jnXt2lXff/+9pMqV59577z3dfffdSk5O1r///W/16NFDkhQeHq7PP/9cv/3tb3XhhRcqPDxcEydO1PPPP1/ztW699VaVlpbqhRde0O9//3u1atVKP/3pT733BwQA+BxWtwMA+C2bzaZZs2ZpwoQJpqMAAAII9yQBAAAAQC2UJAAAAACohXuSAAB+ixnjAICmwJUkAAAAAKiFkgQAAAAAtVCSAAAAAKAWShIAAAAA1EJJAgAAAIBaKEkAAAAAUAslCQAAAABqoSQBAAAAQC3/Hy303mUug2XUAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2608c894"
      },
      "source": [
        "### Chosen Dataset: WMT English-French Translation Subset\n",
        "\n",
        "We will use a subset of the WMT English-French translation dataset. This dataset consists of pairs of sentences, one in English and its corresponding translation in French. It's a good choice because:\n",
        "\n",
        "*   It's a standard dataset used in many NLP tasks, including machine translation.\n",
        "*   It's a sequence-to-sequence problem, which the Transformer is well-suited for.\n",
        "*   Smaller subsets are available, making it manageable for this demonstration without requiring extensive computational resources."
      ]
    }
  ]
}