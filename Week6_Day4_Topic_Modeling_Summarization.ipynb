{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6, Day 4: Topic Modeling and Text Summarization\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand topic modeling concepts\n",
    "- Learn text summarization techniques\n",
    "- Master document clustering\n",
    "- Practice implementing topic models\n",
    "\n",
    "## Topics Covered\n",
    "1. Topic Modeling\n",
    "2. Text Summarization\n",
    "3. Document Clustering\n",
    "4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.summarization import summarize\n",
    "import gensim\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def topic_modeling_example():\n",
    "    # Sample documents\n",
    "    documents = [\n",
    "        \"Machine learning algorithms help computers learn from data.\",\n",
    "        \"Deep learning models have revolutionized AI applications.\",\n",
    "        \"Neural networks are inspired by biological brains.\",\n",
    "        \"Data science combines statistics and programming.\",\n",
    "        \"Python is a popular programming language for AI.\",\n",
    "        \"Statistical methods are fundamental to data analysis.\",\n",
    "        \"Natural language processing helps computers understand text.\",\n",
    "        \"Computer vision systems can recognize images and video.\",\n",
    "        \"Reinforcement learning enables autonomous decision making.\",\n",
    "        \"Big data analytics requires efficient processing systems.\"\n",
    "    ]\n",
    "    \n",
    "    # Create document-term matrix\n",
    "    vectorizer = CountVectorizer(max_features=1000, stop_words='english')\n",
    "    doc_term_matrix = vectorizer.fit_transform(documents)\n",
    "    \n",
    "    # Apply LDA\n",
    "    n_topics = 3\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "    doc_topics = lda.fit_transform(doc_term_matrix)\n",
    "    \n",
    "    # Get feature names\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Print top words for each topic\n",
    "    n_top_words = 5\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]\n",
    "        print(f\"Topic {topic_idx + 1}: {', '.join(top_words)}\")\n",
    "    \n",
    "    # Visualize topic distribution\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Document-Topic Distribution\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(doc_topics, aspect='auto', cmap='YlOrRd')\n",
    "    plt.title('Document-Topic Distribution')\n",
    "    plt.xlabel('Topic')\n",
    "    plt.ylabel('Document')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Topic Proportions\n",
    "    plt.subplot(122)\n",
    "    topic_proportions = doc_topics.mean(axis=0)\n",
    "    plt.bar(range(1, n_topics + 1), topic_proportions)\n",
    "    plt.title('Topic Proportions')\n",
    "    plt.xlabel('Topic')\n",
    "    plt.ylabel('Proportion')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "topic_modeling_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def text_summarization_example():\n",
    "    # Sample text\n",
    "    text = \"\"\"\n",
    "    Artificial Intelligence (AI) has transformed various industries in recent years.\n",
    "    Machine learning algorithms enable computers to learn from data and improve their performance.\n",
    "    Deep learning, a subset of machine learning, has achieved remarkable results in tasks like image recognition and natural language processing.\n",
    "    Neural networks, inspired by biological brains, form the basis of deep learning systems.\n",
    "    These networks can automatically learn hierarchical representations of data.\n",
    "    Applications of AI include autonomous vehicles, medical diagnosis, and personal assistants.\n",
    "    However, challenges remain in areas such as ethics, bias, and transparency.\n",
    "    Researchers continue to work on making AI systems more reliable and interpretable.\n",
    "    The future of AI holds great promise for solving complex problems.\n",
    "    Continued development of AI technology will likely lead to more breakthroughs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extractive summarization\n",
    "    def extractive_summarize(text, n_sentences=3):\n",
    "        # Tokenize sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "        \n",
    "        # Create TF-IDF matrix\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "        \n",
    "        # Calculate sentence scores\n",
    "        sentence_scores = tfidf_matrix.sum(axis=1).A1\n",
    "        \n",
    "        # Get top sentences\n",
    "        top_indices = sentence_scores.argsort()[-n_sentences:][::-1]\n",
    "        summary = ' '.join([sentences[i] for i in sorted(top_indices)])\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = extractive_summarize(text)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Original Text:\")\n",
    "    print(text)\n",
    "    print(\"\\nSummary:\")\n",
    "    print(summary)\n",
    "    \n",
    "    # Analyze compression\n",
    "    original_words = len(word_tokenize(text))\n",
    "    summary_words = len(word_tokenize(summary))\n",
    "    compression_ratio = summary_words / original_words\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(['Original', 'Summary'], [original_words, summary_words])\n",
    "    plt.title(f'Text Compression (Ratio: {compression_ratio:.2f})')\n",
    "    plt.ylabel('Word Count')\n",
    "    plt.show()\n",
    "\n",
    "text_summarization_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def document_clustering_example():\n",
    "    # Sample documents\n",
    "    documents = [\n",
    "        \"Python programming basics for beginners\",\n",
    "        \"Machine learning algorithms in Python\",\n",
    "        \"Data structures and algorithms\",\n",
    "        \"Neural networks and deep learning\",\n",
    "        \"Python web development frameworks\",\n",
    "        \"Introduction to programming concepts\",\n",
    "        \"Deep learning for computer vision\",\n",
    "        \"Web development best practices\",\n",
    "        \"Algorithm optimization techniques\",\n",
    "        \"Python libraries for data science\"\n",
    "    ]\n",
    "    \n",
    "    # Create TF-IDF matrix\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    \n",
    "    # Apply K-means clustering\n",
    "    n_clusters = 3\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(tfidf_matrix)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Document': documents,\n",
    "        'Cluster': clusters\n",
    "    })\n",
    "    \n",
    "    # Print clusters\n",
    "    for cluster in range(n_clusters):\n",
    "        print(f\"\\nCluster {cluster + 1}:\")\n",
    "        for doc in df[df['Cluster'] == cluster]['Document']:\n",
    "            print(f\"- {doc}\")\n",
    "    \n",
    "    # Visualize clusters\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    # Reduce dimensionality for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    coords = pca.fit_transform(tfidf_matrix.toarray())\n",
    "    \n",
    "    # Plot clusters\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    scatter = plt.scatter(coords[:, 0], coords[:, 1], c=clusters, cmap='viridis')\n",
    "    plt.title('Document Clusters')\n",
    "    plt.colorbar(scatter)\n",
    "    plt.show()\n",
    "\n",
    "document_clustering_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 1: Advanced Topic Modeling\n",
    "\n",
    "def topic_modeling_exercise():\n",
    "    # Sample articles\n",
    "    articles = [\n",
    "        \"\"\"The latest advances in artificial intelligence have led to significant\n",
    "        breakthroughs in natural language processing and computer vision...\"\"\",\n",
    "        \"\"\"Climate change continues to affect global weather patterns, leading to\n",
    "        more extreme weather events and rising sea levels...\"\"\",\n",
    "        \"\"\"Researchers have discovered new potential treatments for cancer using\n",
    "        targeted immunotherapy approaches...\"\"\",\n",
    "        # Add more articles...\n",
    "    ]\n",
    "    \n",
    "    print(\"Task: Implement advanced topic modeling\")\n",
    "    print(\"1. Preprocess the articles\")\n",
    "    print(\"2. Apply different topic modeling methods\")\n",
    "    print(\"3. Compare results\")\n",
    "    print(\"4. Visualize topics\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "topic_modeling_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 2: Custom Summarizer\n",
    "\n",
    "def summarization_exercise():\n",
    "    # Sample long text\n",
    "    text = \"\"\"\n",
    "    [Your long text here with multiple paragraphs discussing a topic in detail...]\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Task: Create a custom summarization system\")\n",
    "    print(\"1. Implement sentence scoring\")\n",
    "    print(\"2. Select important sentences\")\n",
    "    print(\"3. Generate summary\")\n",
    "    print(\"4. Evaluate quality\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "summarization_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCQ Quiz\n",
    "\n",
    "1. What is topic modeling?\n",
    "   - a) Text classification\n",
    "   - b) Topic discovery\n",
    "   - c) Text generation\n",
    "   - d) Language translation\n",
    "\n",
    "2. What is LDA used for?\n",
    "   - a) Text summarization\n",
    "   - b) Topic modeling\n",
    "   - c) Machine translation\n",
    "   - d) Sentiment analysis\n",
    "\n",
    "3. What type of summarization is extractive?\n",
    "   - a) Generating new text\n",
    "   - b) Selecting existing sentences\n",
    "   - c) Translating text\n",
    "   - d) Paraphrasing\n",
    "\n",
    "4. What is document clustering?\n",
    "   - a) Text generation\n",
    "   - b) Document grouping\n",
    "   - c) Translation\n",
    "   - d) Summarization\n",
    "\n",
    "5. What is perplexity in topic modeling?\n",
    "   - a) Number of topics\n",
    "   - b) Model quality measure\n",
    "   - c) Text length\n",
    "   - d) Word count\n",
    "\n",
    "6. Which algorithm is NOT for topic modeling?\n",
    "   - a) LDA\n",
    "   - b) NMF\n",
    "   - c) K-means\n",
    "   - d) LSA\n",
    "\n",
    "7. What is coherence score?\n",
    "   - a) Text length\n",
    "   - b) Topic quality measure\n",
    "   - c) Word count\n",
    "   - d) Document length\n",
    "\n",
    "8. What is abstractive summarization?\n",
    "   - a) Sentence selection\n",
    "   - b) New text generation\n",
    "   - c) Word counting\n",
    "   - d) Text clustering\n",
    "\n",
    "9. What is silhouette score used for?\n",
    "   - a) Topic modeling\n",
    "   - b) Cluster evaluation\n",
    "   - c) Text generation\n",
    "   - d) Summarization\n",
    "\n",
    "10. What is the purpose of dimensionality reduction?\n",
    "    - a) Text generation\n",
    "    - b) Data visualization\n",
    "    - c) Translation\n",
    "    - d) Summarization\n",
    "\n",
    "Answers: 1-b, 2-b, 3-b, 4-b, 5-b, 6-c, 7-b, 8-b, 9-b, 10-b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}