{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9, Day 3: Diffusion Models\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand diffusion model concepts\n",
    "- Learn denoising process\n",
    "- Master diffusion architectures\n",
    "- Practice implementing diffusion models\n",
    "\n",
    "## Topics Covered\n",
    "1. Diffusion Process\n",
    "2. Denoising Models\n",
    "3. Score-Based Models\n",
    "4. Advanced Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class DiffusionModel:\n",
    "    def __init__(self, timesteps=1000):\n",
    "        self.timesteps = timesteps\n",
    "        \n",
    "        # Define noise schedule\n",
    "        self.beta = np.linspace(0.0001, 0.02, timesteps)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_bar = np.cumprod(self.alpha)\n",
    "        \n",
    "        # Build model\n",
    "        self.model = self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        # U-Net architecture\n",
    "        inputs = layers.Input(shape=(32, 32, 1))\n",
    "        x = inputs\n",
    "        \n",
    "        # Encoder\n",
    "        skips = []\n",
    "        for filters in [64, 128, 256]:\n",
    "            x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.ReLU()(x)\n",
    "            skips.append(x)\n",
    "            x = layers.MaxPooling2D()(x)\n",
    "        \n",
    "        # Middle\n",
    "        x = layers.Conv2D(512, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        \n",
    "        # Decoder\n",
    "        for filters, skip in zip([256, 128, 64], reversed(skips)):\n",
    "            x = layers.UpSampling2D()(x)\n",
    "            x = layers.Concatenate()([x, skip])\n",
    "            x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.ReLU()(x)\n",
    "        \n",
    "        outputs = layers.Conv2D(1, 3, padding='same')(x)\n",
    "        \n",
    "        return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    def diffusion_forward(self, x0, t):\n",
    "        \"\"\"Forward diffusion process\"\"\"\n",
    "        noise = tf.random.normal(shape=x0.shape)\n",
    "        alpha_t = tf.gather(self.alpha_bar, t)\n",
    "        alpha_t = tf.reshape(alpha_t, (-1, 1, 1, 1))\n",
    "        return tf.sqrt(alpha_t) * x0 + tf.sqrt(1. - alpha_t) * noise, noise\n",
    "    \n",
    "    def diffusion_reverse(self, xt, t):\n",
    "        \"\"\"Reverse diffusion process\"\"\"\n",
    "        predicted_noise = self.model(xt, training=False)\n",
    "        alpha_t = tf.gather(self.alpha_bar, t)\n",
    "        alpha_t = tf.reshape(alpha_t, (-1, 1, 1, 1))\n",
    "        beta_t = tf.gather(self.beta, t)\n",
    "        beta_t = tf.reshape(beta_t, (-1, 1, 1, 1))\n",
    "        \n",
    "        mean = (1. / tf.sqrt(alpha_t)) * (xt - ((1. - alpha_t) / tf.sqrt(1. - alpha_t)) * predicted_noise)\n",
    "        variance = beta_t\n",
    "        \n",
    "        return mean + tf.sqrt(variance) * tf.random.normal(shape=xt.shape)\n",
    "    \n",
    "    def sample(self, batch_size=16):\n",
    "        \"\"\"Generate samples using the reverse process\"\"\"\n",
    "        # Start from pure noise\n",
    "        x = tf.random.normal(shape=(batch_size, 32, 32, 1))\n",
    "        \n",
    "        # Reverse diffusion\n",
    "        for t in reversed(range(self.timesteps)):\n",
    "            x = self.diffusion_reverse(x, t)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Score-Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ScoreBasedModel:\n",
    "    def __init__(self):\n",
    "        self.model = self.build_score_model()\n",
    "        \n",
    "    def build_score_model(self):\n",
    "        inputs = layers.Input(shape=(32, 32, 1))\n",
    "        x = inputs\n",
    "        \n",
    "        # Downsampling\n",
    "        for filters in [64, 128, 256]:\n",
    "            x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "            x = layers.GroupNormalization()(x)\n",
    "            x = layers.Activation('swish')(x)\n",
    "            x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "            x = layers.GroupNormalization()(x)\n",
    "            x = layers.Activation('swish')(x)\n",
    "            x = layers.AveragePooling2D()(x)\n",
    "        \n",
    "        # Middle\n",
    "        x = layers.Conv2D(512, 3, padding='same')(x)\n",
    "        x = layers.GroupNormalization()(x)\n",
    "        x = layers.Activation('swish')(x)\n",
    "        \n",
    "        # Upsampling\n",
    "        for filters in [256, 128, 64]:\n",
    "            x = layers.UpSampling2D()(x)\n",
    "            x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "            x = layers.GroupNormalization()(x)\n",
    "            x = layers.Activation('swish')(x)\n",
    "            x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "            x = layers.GroupNormalization()(x)\n",
    "            x = layers.Activation('swish')(x)\n",
    "        \n",
    "        outputs = layers.Conv2D(1, 3, padding='same')(x)\n",
    "        \n",
    "        return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    def score_matching_loss(self, x, sigma):\n",
    "        \"\"\"Denoising score matching loss\"\"\"\n",
    "        noise = tf.random.normal(shape=x.shape)\n",
    "        perturbed_x = x + sigma * noise\n",
    "        score = self.model(perturbed_x)\n",
    "        target = -noise / sigma\n",
    "        return tf.reduce_mean(tf.square(score - target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_diffusion_model(model, dataset, epochs=100):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataset:\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Sample timestep\n",
    "                t = tf.random.uniform(\n",
    "                    shape=(batch.shape[0],),\n",
    "                    minval=0,\n",
    "                    maxval=model.timesteps,\n",
    "                    dtype=tf.int32\n",
    "                )\n",
    "                \n",
    "                # Forward process\n",
    "                noisy_batch, noise = model.diffusion_forward(batch, t)\n",
    "                \n",
    "                # Predict noise\n",
    "                predicted_noise = model.model(noisy_batch, training=True)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = tf.reduce_mean(tf.square(noise - predicted_noise))\n",
    "            \n",
    "            # Update model\n",
    "            grads = tape.gradient(loss, model.model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.model.trainable_variables))\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "            \n",
    "            # Generate samples\n",
    "            samples = model.sample(batch_size=4)\n",
    "            \n",
    "            # Plot samples\n",
    "            plt.figure(figsize=(8, 2))\n",
    "            for i in range(4):\n",
    "                plt.subplot(1, 4, i+1)\n",
    "                plt.imshow(samples[i, ..., 0], cmap='gray')\n",
    "                plt.axis('off')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 1: Simple Diffusion\n",
    "\n",
    "def diffusion_exercise():\n",
    "    print(\"Task: Implement basic diffusion model\")\n",
    "    print(\"1. Create noise schedule\")\n",
    "    print(\"2. Implement forward process\")\n",
    "    print(\"3. Implement reverse process\")\n",
    "    print(\"4. Generate samples\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "diffusion_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 2: Score Matching\n",
    "\n",
    "def score_matching_exercise():\n",
    "    print(\"Task: Implement score-based model\")\n",
    "    print(\"1. Create score network\")\n",
    "    print(\"2. Implement score matching\")\n",
    "    print(\"3. Train model\")\n",
    "    print(\"4. Generate samples\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "score_matching_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCQ Quiz\n",
    "\n",
    "1. What is a diffusion model?\n",
    "   - a) Classification model\n",
    "   - b) Noise-based generation\n",
    "   - c) Regression model\n",
    "   - d) Clustering model\n",
    "\n",
    "2. What is the forward process?\n",
    "   - a) Generation\n",
    "   - b) Noise addition\n",
    "   - c) Classification\n",
    "   - d) Regression\n",
    "\n",
    "3. What is the reverse process?\n",
    "   - a) Noise addition\n",
    "   - b) Denoising\n",
    "   - c) Classification\n",
    "   - d) Regression\n",
    "\n",
    "4. What is score matching?\n",
    "   - a) Classification\n",
    "   - b) Gradient learning\n",
    "   - c) Regression\n",
    "   - d) Clustering\n",
    "\n",
    "5. What is the noise schedule?\n",
    "   - a) Random noise\n",
    "   - b) Noise parameters\n",
    "   - c) Model architecture\n",
    "   - d) Loss function\n",
    "\n",
    "6. What is denoising diffusion?\n",
    "   - a) Noise addition\n",
    "   - b) Generation process\n",
    "   - c) Classification\n",
    "   - d) Regression\n",
    "\n",
    "7. What is a U-Net?\n",
    "   - a) Loss function\n",
    "   - b) Network architecture\n",
    "   - c) Optimization method\n",
    "   - d) Sampling strategy\n",
    "\n",
    "8. What is timestep embedding?\n",
    "   - a) Loss function\n",
    "   - b) Time conditioning\n",
    "   - c) Model architecture\n",
    "   - d) Sampling method\n",
    "\n",
    "9. What is guidance?\n",
    "   - a) Training method\n",
    "   - b) Generation control\n",
    "   - c) Loss function\n",
    "   - d) Model architecture\n",
    "\n",
    "10. What is ancestral sampling?\n",
    "    - a) Training method\n",
    "    - b) Sampling strategy\n",
    "    - c) Loss function\n",
    "    - d) Model architecture\n",
    "\n",
    "Answers: 1-b, 2-b, 3-b, 4-b, 5-b, 6-b, 7-b, 8-b, 9-b, 10-b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}