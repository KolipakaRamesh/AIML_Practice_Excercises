{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9, Day 6: Generative AI Hackathon Challenge\n",
    "\n",
    "## Challenge Overview\n",
    "Build an end-to-end generative AI solution using concepts learned throughout Week 9:\n",
    "- Generative Models\n",
    "- GANs and VAEs\n",
    "- Diffusion Models\n",
    "- Language Models\n",
    "- Advanced NLP\n",
    "\n",
    "## Problem: Multi-Modal Generation System\n",
    "Create a system that can generate multiple types of content:\n",
    "1. Text Generation\n",
    "2. Image Generation\n",
    "3. Text-to-Image Generation\n",
    "4. Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Text Generation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class TextGenerator:\n",
    "    def __init__(self):\n",
    "        # Initialize text generation pipeline\n",
    "        self.generator = pipeline('text-generation', model='gpt2')\n",
    "    \n",
    "    def generate(self, prompt, max_length=100, num_samples=1, temperature=0.7):\n",
    "        \"\"\"Generate text based on prompt\"\"\"\n",
    "        outputs = self.generator(\n",
    "            prompt,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=num_samples,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return [out['generated_text'] for out in outputs]\n",
    "    \n",
    "    def batch_generate(self, prompts, **kwargs):\n",
    "        \"\"\"Generate text for multiple prompts\"\"\"\n",
    "        all_outputs = []\n",
    "        for prompt in prompts:\n",
    "            outputs = self.generate(prompt, **kwargs)\n",
    "            all_outputs.extend(outputs)\n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Image Generation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ImageGenerator:\n",
    "    def __init__(self):\n",
    "        # Initialize image generation model\n",
    "        self.model = self.build_generator()\n",
    "    \n",
    "    def build_generator(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            # Latent space input\n",
    "            tf.keras.layers.Input(shape=(100,)),\n",
    "            \n",
    "            # Dense layer and reshape\n",
    "            tf.keras.layers.Dense(8*8*256),\n",
    "            tf.keras.layers.Reshape((8, 8, 256)),\n",
    "            \n",
    "            # Upsampling blocks\n",
    "            tf.keras.layers.Conv2DTranspose(128, 4, strides=2, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            tf.keras.layers.Conv2DTranspose(64, 4, strides=2, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            tf.keras.layers.Conv2DTranspose(32, 4, strides=2, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            # Output layer\n",
    "            tf.keras.layers.Conv2D(3, 4, padding='same', activation='tanh')\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def generate(self, num_images=1):\n",
    "        \"\"\"Generate random images\"\"\"\n",
    "        noise = tf.random.normal([num_images, 100])\n",
    "        generated_images = self.model(noise, training=False)\n",
    "        return generated_images\n",
    "    \n",
    "    def generate_and_plot(self, num_images=4):\n",
    "        \"\"\"Generate and display images\"\"\"\n",
    "        images = self.generate(num_images)\n",
    "        \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for i in range(num_images):\n",
    "            plt.subplot(2, 2, i+1)\n",
    "            plt.imshow(images[i] * 0.5 + 0.5)\n",
    "            plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Text-to-Image System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class TextToImageGenerator:\n",
    "    def __init__(self):\n",
    "        # Initialize text encoder and image decoder\n",
    "        self.text_encoder = self.build_text_encoder()\n",
    "        self.image_decoder = self.build_image_decoder()\n",
    "    \n",
    "    def build_text_encoder(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(100,)),  # Tokenized text\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(1024)\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def build_image_decoder(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(1024,)),\n",
    "            tf.keras.layers.Dense(8*8*256),\n",
    "            tf.keras.layers.Reshape((8, 8, 256)),\n",
    "            \n",
    "            tf.keras.layers.Conv2DTranspose(128, 4, strides=2, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            tf.keras.layers.Conv2DTranspose(64, 4, strides=2, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            tf.keras.layers.Conv2DTranspose(32, 4, strides=2, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(3, 4, padding='same', activation='tanh')\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def generate(self, text_embedding):\n",
    "        \"\"\"Generate image from text embedding\"\"\"\n",
    "        encoded_text = self.text_encoder(text_embedding)\n",
    "        generated_image = self.image_decoder(encoded_text)\n",
    "        return generated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Style Transfer System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class StyleTransfer:\n",
    "    def __init__(self):\n",
    "        # Initialize style transfer model\n",
    "        self.model = self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            # Content encoder\n",
    "            tf.keras.layers.Input(shape=(256, 256, 3)),\n",
    "            tf.keras.layers.Conv2D(32, 3, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            \n",
    "            # Style encoder\n",
    "            tf.keras.layers.Conv2D(64, 3, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            \n",
    "            # Transformer\n",
    "            tf.keras.layers.Conv2D(128, 3, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            \n",
    "            # Decoder\n",
    "            tf.keras.layers.Conv2D(64, 3, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(32, 3, padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(3, 3, padding='same', activation='tanh')\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def transfer_style(self, content_image, style_image):\n",
    "        \"\"\"Apply style transfer\"\"\"\n",
    "        # Preprocess images\n",
    "        content = tf.image.resize(content_image, [256, 256])\n",
    "        style = tf.image.resize(style_image, [256, 256])\n",
    "        \n",
    "        # Combine and process\n",
    "        combined = tf.concat([content, style], axis=-1)\n",
    "        result = self.model(combined)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Criteria\n",
    "\n",
    "Your solution will be evaluated based on:\n",
    "\n",
    "1. Text Generation (25%)\n",
    "   - Text quality\n",
    "   - Coherence\n",
    "   - Diversity\n",
    "\n",
    "2. Image Generation (25%)\n",
    "   - Image quality\n",
    "   - Diversity\n",
    "   - Resolution\n",
    "\n",
    "3. Text-to-Image (25%)\n",
    "   - Alignment\n",
    "   - Quality\n",
    "   - Creativity\n",
    "\n",
    "4. Style Transfer (25%)\n",
    "   - Style fidelity\n",
    "   - Content preservation\n",
    "   - Transfer quality\n",
    "\n",
    "## Submission Guidelines\n",
    "1. Complete all tasks in this notebook\n",
    "2. Document your approach and decisions\n",
    "3. Include visualizations and examples\n",
    "4. Provide suggestions for improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}