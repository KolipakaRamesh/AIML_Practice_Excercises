{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0/9tsjPl6N1xy5X5Bb4Iy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KolipakaRamesh/AIML_Practice_Excercises/blob/main/TestAgent1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOFrZkWbFlzs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4c2801d",
        "outputId": "f41b2725-b3a8-4c72-8fe9-a41d2e7aef8f"
      },
      "source": [
        "class SimpleAgent:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def greet(self):\n",
        "        print(f\"Hello, I am {self.name}!\")\n",
        "\n",
        "# Create an instance of the agent\n",
        "my_agent = SimpleAgent(\"Greeting Agent\")\n",
        "\n",
        "# Make the agent perform its task\n",
        "my_agent.greet()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am Greeting Agent!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36a02f8b",
        "outputId": "e564c66c-ad96-4577-e284-c7f8970164d0"
      },
      "source": [
        "%pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "846221d0",
        "outputId": "4c7cf57e-e60b-4f2d-abe7-472f5e12e61f"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "class TextGeneratingAgent:\n",
        "    def __init__(self, model_name=\"distilgpt2\"):\n",
        "        self.generator = pipeline(\"text-generation\", model=model_name)\n",
        "        self.name = f\"Text Generating Agent ({model_name})\"\n",
        "\n",
        "    def generate_text(self, prompt, max_length=50):\n",
        "        print(f\"{self.name} is generating text based on the prompt: '{prompt}'\")\n",
        "        result = self.generator(prompt, max_length=max_length, num_return_sequences=1)\n",
        "        return result[0]['generated_text']\n",
        "\n",
        "# Create an instance of the agent with a pre-trained model\n",
        "my_text_agent = TextGeneratingAgent()\n",
        "\n",
        "# Make the agent generate text\n",
        "prompt = \"N-gram models of ai\"\n",
        "generated_story = my_text_agent.generate_text(prompt)\n",
        "print(\"\\nGenerated Text:\")\n",
        "print(generated_story)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Generating Agent (distilgpt2) is generating text based on the prompt: 'N-gram models of ai'\n",
            "\n",
            "Generated Text:\n",
            "N-gram models of ai2, it makes sense. Since the model is a standard in the world of classical physics, it was invented by H. Henschler in 1903. So what does that mean?\n",
            "\n",
            "\n",
            "The main idea is that the model is a quantum mechanical system. There is a physical physical structure in which we know that the model is a quantum state. What we know is that it is a quantum mechanical system. And that is the basic principle of quantum mechanics. In fact, it has a quantum mechanical system. And that is the fundamental principle of quantum mechanics.\n",
            "We know that the model is a quantum mechanical system, the physical structure. And that is the fundamental principle of quantum mechanics. And that is the basic principle of quantum mechanics.\n",
            "So what does that mean?\n",
            "That is, the fundamental principle of quantum mechanics. And that is the basic principle of quantum mechanics. And that is the fundamental principle of quantum mechanics. And that is the quantum mechanical system. And that is the fundamental principle of quantum mechanics. And that is the fundamental principle of quantum mechanics.\n",
            "So what does that mean?\n",
            "That is the fundamental principle of quantum mechanics. And that is the fundamental principle of quantum mechanics. And that is the fundamental principle of quantum mechanics. And that is\n"
          ]
        }
      ]
    }
  ]
}