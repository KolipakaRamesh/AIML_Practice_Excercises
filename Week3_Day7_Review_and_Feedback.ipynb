{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3, Day 7: Review and Feedback Session\n",
    "\n",
    "## Session Overview\n",
    "This session will review the key concepts covered in Week 3 and provide practice exercises to reinforce learning:\n",
    "\n",
    "1. Introduction to Machine Learning\n",
    "2. Linear Regression\n",
    "3. Logistic Regression\n",
    "4. Decision Trees and Random Forests\n",
    "5. Support Vector Machines\n",
    "\n",
    "## Learning Objectives\n",
    "- Reinforce key ML concepts\n",
    "- Practice model selection\n",
    "- Master model evaluation\n",
    "- Prepare for Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Selection Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def model_selection_review():\n",
    "    # Generate different types of data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 300\n",
    "    \n",
    "    # Linear relationship\n",
    "    X_linear = np.random.rand(n_samples, 1) * 10\n",
    "    y_linear = 2 * X_linear + 1 + np.random.randn(n_samples, 1) * 0.5\n",
    "    \n",
    "    # Nonlinear relationship\n",
    "    X_nonlinear = np.random.rand(n_samples, 1) * 10\n",
    "    y_nonlinear = np.sin(X_nonlinear) + np.random.randn(n_samples, 1) * 0.2\n",
    "    \n",
    "    # Classification data\n",
    "    X_class = np.random.randn(n_samples, 2)\n",
    "    y_class = (X_class[:, 0] + X_class[:, 1] > 0).astype(int)\n",
    "    \n",
    "    # Visualize datasets\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.scatter(X_linear, y_linear)\n",
    "    plt.title('Linear Relationship')\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.scatter(X_nonlinear, y_nonlinear)\n",
    "    plt.title('Nonlinear Relationship')\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.scatter(X_class[:, 0], X_class[:, 1], c=y_class)\n",
    "    plt.title('Classification Data')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Which model would you choose for each dataset?\")\n",
    "    print(\"1. Linear data: Linear Regression\")\n",
    "    print(\"2. Nonlinear data: Decision Trees or SVMs with nonlinear kernel\")\n",
    "    print(\"3. Classification data: Logistic Regression or SVM\")\n",
    "\n",
    "model_selection_review()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Evaluation Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def model_evaluation_review():\n",
    "    # Generate sample classification data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Create features\n",
    "    X = np.random.randn(n_samples, 3)\n",
    "    y = (np.sum(X**2, axis=1) > 3).astype(int)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train different models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=42),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(random_state=42),\n",
    "        'SVM': SVC(random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Evaluate models\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.append({'Model': name, 'Accuracy': accuracy})\n",
    "        \n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Visualize results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=results_df, x='Model', y='Accuracy')\n",
    "    plt.title('Model Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "model_evaluation_review()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Practice Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def comprehensive_exercise():\n",
    "    # Generate synthetic dataset\n",
    "    np.random.seed(42)\n",
    "    n_samples = 500\n",
    "    \n",
    "    # Create features\n",
    "    X = np.random.randn(n_samples, 4)\n",
    "    # Add some noise and nonlinearity\n",
    "    y = (X[:, 0]**2 + np.exp(X[:, 1]) + X[:, 2] * X[:, 3] + np.random.randn(n_samples) * 0.1)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"Exercise Tasks:\")\n",
    "    print(\"1. Analyze the relationship between features and target\")\n",
    "    print(\"2. Select appropriate model(s)\")\n",
    "    print(\"3. Train and evaluate models\")\n",
    "    print(\"4. Optimize the best performing model\")\n",
    "    print(\"5. Provide insights and recommendations\")\n",
    "    \n",
    "    # Your solution here\n",
    "\n",
    "comprehensive_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3 Review Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Choice Questions\n",
    "\n",
    "1. Which model is best for linear regression?\n",
    "   - a) Decision Trees\n",
    "   - b) Linear Regression\n",
    "   - c) SVM\n",
    "   - d) Random Forest\n",
    "\n",
    "2. What is the output range of logistic regression?\n",
    "   - a) -∞ to +∞\n",
    "   - b) 0 to 1\n",
    "   - c) -1 to 1\n",
    "   - d) 0 to ∞\n",
    "\n",
    "3. Which model is most interpretable?\n",
    "   - a) Neural Networks\n",
    "   - b) Decision Trees\n",
    "   - c) Random Forest\n",
    "   - d) SVM\n",
    "\n",
    "4. What does the C parameter in SVM control?\n",
    "   - a) Learning rate\n",
    "   - b) Regularization\n",
    "   - c) Number of trees\n",
    "   - d) Kernel type\n",
    "\n",
    "5. Which metric is used for regression problems?\n",
    "   - a) Accuracy\n",
    "   - b) Precision\n",
    "   - c) MSE\n",
    "   - d) F1-score\n",
    "\n",
    "6. What is bagging?\n",
    "   - a) Feature selection\n",
    "   - b) Ensemble method\n",
    "   - c) Data cleaning\n",
    "   - d) Model evaluation\n",
    "\n",
    "7. Which kernel is best for nonlinear data?\n",
    "   - a) Linear\n",
    "   - b) RBF\n",
    "   - c) Identity\n",
    "   - d) None\n",
    "\n",
    "8. What is overfitting?\n",
    "   - a) High bias\n",
    "   - b) High variance\n",
    "   - c) Low accuracy\n",
    "   - d) Low precision\n",
    "\n",
    "9. Which is NOT a hyperparameter in Random Forest?\n",
    "   - a) n_estimators\n",
    "   - b) max_depth\n",
    "   - c) learning_rate\n",
    "   - d) min_samples_split\n",
    "\n",
    "10. What is cross-validation used for?\n",
    "    - a) Feature scaling\n",
    "    - b) Model evaluation\n",
    "    - c) Data cleaning\n",
    "    - d) Feature selection\n",
    "\n",
    "Answers: 1-b, 2-b, 3-b, 4-b, 5-c, 6-b, 7-b, 8-b, 9-c, 10-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3 Summary\n",
    "\n",
    "### Key Concepts Covered:\n",
    "1. Machine Learning fundamentals and workflow\n",
    "2. Supervised Learning algorithms\n",
    "3. Model selection and evaluation\n",
    "4. Parameter tuning and optimization\n",
    "\n",
    "### Preparation for Week 4:\n",
    "- Review challenging concepts\n",
    "- Practice model implementation\n",
    "- Prepare for unsupervised learning\n",
    "- Review Python and scikit-learn\n",
    "\n",
    "### Additional Resources:\n",
    "- Scikit-learn documentation: https://scikit-learn.org/stable/\n",
    "- Machine Learning crash course: https://developers.google.com/machine-learning/crash-course\n",
    "- Feature engineering guide: https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}