{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6, Day 2: Text Classification and Sentiment Analysis\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand text classification concepts\n",
    "- Learn sentiment analysis techniques\n",
    "- Master feature engineering for text\n",
    "- Practice implementing classifiers\n",
    "\n",
    "## Topics Covered\n",
    "1. Text Classification Basics\n",
    "2. Feature Engineering\n",
    "3. Sentiment Analysis\n",
    "4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Classification Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def text_classification_example():\n",
    "    # Sample dataset\n",
    "    texts = [\n",
    "        \"This movie was fantastic! Great acting and plot.\",\n",
    "        \"Terrible waste of time. Poor acting and boring story.\",\n",
    "        \"Amazing film, highly recommended!\",\n",
    "        \"Don't waste your money on this movie.\",\n",
    "        \"Excellent performance by the entire cast.\",\n",
    "        \"One of the worst movies I've ever seen.\",\n",
    "        \"A masterpiece of modern cinema.\",\n",
    "        \"Complete disappointment, save your time.\",\n",
    "        \"Brilliant direction and storytelling.\",\n",
    "        \"Awful plot, terrible acting, avoid at all costs.\"\n",
    "    ]\n",
    "    \n",
    "    labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]  # 1: positive, 0: negative\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        texts, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create TF-IDF features\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Train models\n",
    "    models = {\n",
    "        'Naive Bayes': MultinomialNB(),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'predictions': y_pred,\n",
    "            'report': classification_report(y_test, y_pred)\n",
    "        }\n",
    "    \n",
    "    # Print results\n",
    "    for name, result in results.items():\n",
    "        print(f\"\\nResults for {name}:\")\n",
    "        print(result['report'])\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        cm = confusion_matrix(y_test, result['predictions'])\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "\n",
    "text_classification_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def feature_engineering_example():\n",
    "    # Sample text\n",
    "    text = \"This movie was AMAZING! The acting was great, and I loved the story. Must watch!!!\"\n",
    "    \n",
    "    # Basic features\n",
    "    def extract_features(text):\n",
    "        features = {}\n",
    "        \n",
    "        # Text length\n",
    "        features['text_length'] = len(text)\n",
    "        \n",
    "        # Word count\n",
    "        words = word_tokenize(text)\n",
    "        features['word_count'] = len(words)\n",
    "        \n",
    "        # Average word length\n",
    "        features['avg_word_length'] = np.mean([len(word) for word in words])\n",
    "        \n",
    "        # Uppercase word count\n",
    "        features['uppercase_count'] = sum(1 for word in words if word.isupper())\n",
    "        \n",
    "        # Exclamation mark count\n",
    "        features['exclamation_count'] = text.count('!')\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    # Extract and display features\n",
    "    features = extract_features(text)\n",
    "    \n",
    "    # Plot features\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(features.keys(), features.values())\n",
    "    plt.title('Text Features')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print features\n",
    "    for feature, value in features.items():\n",
    "        print(f\"{feature}: {value}\")\n",
    "\n",
    "feature_engineering_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def sentiment_analysis_example():\n",
    "    # Download NLTK resources\n",
    "    nltk.download('vader_lexicon')\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "    \n",
    "    # Sample reviews\n",
    "    reviews = [\n",
    "        \"This product is amazing! I love everything about it.\",\n",
    "        \"Terrible quality, complete waste of money.\",\n",
    "        \"It's okay, nothing special but gets the job done.\",\n",
    "        \"Could be better, but not the worst I've seen.\",\n",
    "        \"Absolutely fantastic service and product quality!\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Analyze sentiments\n",
    "    results = []\n",
    "    for review in reviews:\n",
    "        scores = sia.polarity_scores(review)\n",
    "        results.append({\n",
    "            'text': review,\n",
    "            'compound': scores['compound'],\n",
    "            'positive': scores['pos'],\n",
    "            'neutral': scores['neu'],\n",
    "            'negative': scores['neg']\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Sentiment distribution\n",
    "    plt.subplot(121)\n",
    "    plt.bar(range(len(df)), df['compound'])\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.title('Compound Sentiment Scores')\n",
    "    plt.xlabel('Review')\n",
    "    plt.ylabel('Score')\n",
    "    \n",
    "    # Sentiment components\n",
    "    plt.subplot(122)\n",
    "    df[['positive', 'neutral', 'negative']].plot(kind='bar', stacked=True)\n",
    "    plt.title('Sentiment Components')\n",
    "    plt.xlabel('Review')\n",
    "    plt.ylabel('Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    for result in results:\n",
    "        print(f\"\\nText: {result['text']}\")\n",
    "        print(f\"Compound Score: {result['compound']:.3f}\")\n",
    "        print(f\"Sentiment: {'Positive' if result['compound'] > 0 else 'Negative' if result['compound'] < 0 else 'Neutral'}\")\n",
    "\n",
    "sentiment_analysis_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 1: Custom Text Classifier\n",
    "\n",
    "def text_classifier_exercise():\n",
    "    # Sample dataset\n",
    "    data = {\n",
    "        'text': [\n",
    "            \"I love this product! Best purchase ever!\",\n",
    "            \"Terrible experience, never buying again.\",\n",
    "            \"Average product, nothing special.\",\n",
    "            \"Great customer service and quality.\",\n",
    "            \"Waste of money, very disappointed.\"\n",
    "        ],\n",
    "        'sentiment': ['positive', 'negative', 'neutral', 'positive', 'negative']\n",
    "    }\n",
    "    \n",
    "    print(\"Task: Build a multi-class sentiment classifier\")\n",
    "    print(\"1. Preprocess the texts\")\n",
    "    print(\"2. Engineer relevant features\")\n",
    "    print(\"3. Train a classifier\")\n",
    "    print(\"4. Evaluate performance\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "text_classifier_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 2: Advanced Feature Engineering\n",
    "\n",
    "def feature_engineering_exercise():\n",
    "    # Sample text\n",
    "    text = \"\"\"\n",
    "    This product is AMAZING! The quality is great and the price is reasonable.\n",
    "    Customer service was very helpful when I had questions. Shipping was fast too!\n",
    "    Definitely recommend this to everyone!!!\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Task: Create advanced text features\")\n",
    "    print(\"1. Design custom features\")\n",
    "    print(\"2. Implement feature extraction\")\n",
    "    print(\"3. Analyze feature importance\")\n",
    "    print(\"4. Visualize results\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "feature_engineering_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCQ Quiz\n",
    "\n",
    "1. What is sentiment analysis?\n",
    "   - a) Text translation\n",
    "   - b) Emotion detection\n",
    "   - c) Grammar checking\n",
    "   - d) Word counting\n",
    "\n",
    "2. Which feature is most important for sentiment analysis?\n",
    "   - a) Text length\n",
    "   - b) Word polarity\n",
    "   - c) Word count\n",
    "   - d) Punctuation\n",
    "\n",
    "3. What is TF-IDF used for?\n",
    "   - a) Text generation\n",
    "   - b) Feature extraction\n",
    "   - c) Sentiment scoring\n",
    "   - d) Grammar checking\n",
    "\n",
    "4. Which classifier is commonly used for text?\n",
    "   - a) K-means\n",
    "   - b) Naive Bayes\n",
    "   - c) Decision Trees\n",
    "   - d) KNN\n",
    "\n",
    "5. What is feature engineering in NLP?\n",
    "   - a) Text generation\n",
    "   - b) Creating useful attributes\n",
    "   - c) Model training\n",
    "   - d) Data collection\n",
    "\n",
    "6. Why use confusion matrix?\n",
    "   - a) Feature selection\n",
    "   - b) Performance evaluation\n",
    "   - c) Text preprocessing\n",
    "   - d) Model training\n",
    "\n",
    "7. What is cross-validation used for?\n",
    "   - a) Feature extraction\n",
    "   - b) Model evaluation\n",
    "   - c) Text cleaning\n",
    "   - d) Sentiment analysis\n",
    "\n",
    "8. Which metric is best for imbalanced data?\n",
    "   - a) Accuracy\n",
    "   - b) F1-score\n",
    "   - c) Error rate\n",
    "   - d) Loss function\n",
    "\n",
    "9. What is overfitting in text classification?\n",
    "   - a) Too few features\n",
    "   - b) Too specific to training\n",
    "   - c) Poor preprocessing\n",
    "   - d) Wrong algorithm\n",
    "\n",
    "10. Why normalize text features?\n",
    "    - a) Increase accuracy\n",
    "    - b) Scale consistency\n",
    "    - c) Reduce memory\n",
    "    - d) Speed up training\n",
    "\n",
    "Answers: 1-b, 2-b, 3-b, 4-b, 5-b, 6-b, 7-b, 8-b, 9-b, 10-b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}