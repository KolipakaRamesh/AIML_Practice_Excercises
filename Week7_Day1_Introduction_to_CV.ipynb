{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7, Day 1: Introduction to Computer Vision\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand computer vision fundamentals\n",
    "- Learn image processing techniques\n",
    "- Master basic CV operations\n",
    "- Practice implementing CV pipelines\n",
    "\n",
    "## Topics Covered\n",
    "1. Image Basics\n",
    "2. Image Processing\n",
    "3. Feature Detection\n",
    "4. Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import io, color, filters, feature\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def image_basics():\n",
    "    # Create sample image\n",
    "    img = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "    img[25:75, 25:75] = [255, 0, 0]  # Red square\n",
    "    \n",
    "    # Show image properties\n",
    "    print(\"Image Shape:\", img.shape)\n",
    "    print(\"Data Type:\", img.dtype)\n",
    "    print(\"Min Value:\", img.min())\n",
    "    print(\"Max Value:\", img.max())\n",
    "    \n",
    "    # Display image\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img)\n",
    "    plt.title('RGB Image')\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(gray, cmap='gray')\n",
    "    plt.title('Grayscale Image')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "image_basics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def image_processing():\n",
    "    # Load sample image\n",
    "    img = cv2.imread('sample.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Basic operations\n",
    "    blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    edges = cv2.Canny(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 100, 200)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Original')\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.imshow(blurred)\n",
    "    plt.title('Blurred')\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.title('Edges')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "image_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def feature_detection():\n",
    "    # Load image\n",
    "    img = cv2.imread('sample.jpg', 0)  # Load as grayscale\n",
    "    \n",
    "    # Detect corners (Harris)\n",
    "    corners = cv2.cornerHarris(img, 2, 3, 0.04)\n",
    "    corners = cv2.dilate(corners, None)\n",
    "    \n",
    "    # SIFT features\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints = sift.detect(img, None)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title('Original')\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.imshow(corners > 0.01 * corners.max(), cmap='gray')\n",
    "    plt.title('Corners')\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    img_keypoints = cv2.drawKeypoints(img, keypoints, None)\n",
    "    plt.imshow(img_keypoints)\n",
    "    plt.title('SIFT Features')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "feature_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def image_transformations():\n",
    "    # Load image\n",
    "    img = cv2.imread('sample.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Transformations\n",
    "    rows, cols = img.shape[:2]\n",
    "    \n",
    "    # Rotation\n",
    "    M_rotation = cv2.getRotationMatrix2D((cols/2, rows/2), 45, 1)\n",
    "    rotated = cv2.warpAffine(img, M_rotation, (cols, rows))\n",
    "    \n",
    "    # Scaling\n",
    "    scaled = cv2.resize(img, None, fx=0.5, fy=0.5)\n",
    "    \n",
    "    # Translation\n",
    "    M_translation = np.float32([[1, 0, 50], [0, 1, 50]])\n",
    "    translated = cv2.warpAffine(img, M_translation, (cols, rows))\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Original')\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.imshow(rotated)\n",
    "    plt.title('Rotated')\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.imshow(scaled)\n",
    "    plt.title('Scaled')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.imshow(translated)\n",
    "    plt.title('Translated')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "image_transformations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 1: Image Processing Pipeline\n",
    "\n",
    "def image_processing_exercise():\n",
    "    # Load image\n",
    "    img = cv2.imread('sample.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    print(\"Task: Create an image processing pipeline\")\n",
    "    print(\"1. Convert to grayscale\")\n",
    "    print(\"2. Apply noise reduction\")\n",
    "    print(\"3. Detect edges\")\n",
    "    print(\"4. Apply thresholding\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "image_processing_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 2: Feature Detection and Matching\n",
    "\n",
    "def feature_matching_exercise():\n",
    "    # Load images\n",
    "    img1 = cv2.imread('image1.jpg')\n",
    "    img2 = cv2.imread('image2.jpg')\n",
    "    \n",
    "    print(\"Task: Implement feature matching\")\n",
    "    print(\"1. Detect features\")\n",
    "    print(\"2. Extract descriptors\")\n",
    "    print(\"3. Match features\")\n",
    "    print(\"4. Visualize matches\")\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "feature_matching_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCQ Quiz\n",
    "\n",
    "1. What is an image in computer vision?\n",
    "   - a) Text file\n",
    "   - b) Matrix of pixels\n",
    "   - c) Video file\n",
    "   - d) Audio signal\n",
    "\n",
    "2. What is grayscale conversion?\n",
    "   - a) Color enhancement\n",
    "   - b) Color to intensity\n",
    "   - c) Image rotation\n",
    "   - d) Edge detection\n",
    "\n",
    "3. What is Gaussian blur used for?\n",
    "   - a) Edge detection\n",
    "   - b) Noise reduction\n",
    "   - c) Feature matching\n",
    "   - d) Color correction\n",
    "\n",
    "4. What is edge detection?\n",
    "   - a) Color change\n",
    "   - b) Intensity change detection\n",
    "   - c) Image rotation\n",
    "   - d) Noise addition\n",
    "\n",
    "5. What is SIFT?\n",
    "   - a) Color space\n",
    "   - b) Feature detector\n",
    "   - c) Image format\n",
    "   - d) Compression method\n",
    "\n",
    "6. What is image thresholding?\n",
    "   - a) Color change\n",
    "   - b) Binary conversion\n",
    "   - c) Edge detection\n",
    "   - d) Noise reduction\n",
    "\n",
    "7. What is affine transformation?\n",
    "   - a) Color correction\n",
    "   - b) Geometric transformation\n",
    "   - c) Edge detection\n",
    "   - d) Feature matching\n",
    "\n",
    "8. What is histogram equalization?\n",
    "   - a) Edge detection\n",
    "   - b) Contrast enhancement\n",
    "   - c) Color conversion\n",
    "   - d) Noise reduction\n",
    "\n",
    "9. What is feature matching?\n",
    "   - a) Color correction\n",
    "   - b) Correspondence finding\n",
    "   - c) Edge detection\n",
    "   - d) Image rotation\n",
    "\n",
    "10. What is morphological operation?\n",
    "    - a) Color change\n",
    "    - b) Shape processing\n",
    "    - c) Edge detection\n",
    "    - d) Feature matching\n",
    "\n",
    "Answers: 1-b, 2-b, 3-b, 4-b, 5-b, 6-b, 7-b, 8-b, 9-b, 10-b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}